{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jan 19 14:39:28 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 511.23       Driver Version: 511.23       CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A    0C    P8    N/A /  N/A |      0MiB /  2048MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n",
      "Tensorflow version 2.7.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.random.set_seed(73)\n",
    "TPU_INIT = False\n",
    "\n",
    "if TPU_INIT:\n",
    "    try:\n",
    "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n",
    "        tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "    \n",
    "    except ValueError:\n",
    "        raise BaseException('ERROR: Not connected to a TPU runtime!')\n",
    "else:\n",
    "    !nvidia-smi\n",
    "    ;    \n",
    "print(\"Tensorflow version \" + tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\python_ml\\\\Wine\\\\video_surveillance\\\\ViolenceDataset'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = os.getcwd() + \"\\\\ViolenceDataset\"\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import imageio\n",
    "import imgaug.augmenters as iaa\n",
    "import imgaug as ia\n",
    "\n",
    "IMG_SIZE = 128\n",
    "ColorChannels = 3\n",
    "\n",
    "def video_to_frames(video):\n",
    "    vidcap = cv2.VideoCapture(video)\n",
    "    \n",
    "    import math\n",
    "    rate = math.floor(vidcap.get(3))\n",
    "    count = 0\n",
    "    \n",
    "    ImageFrames = []\n",
    "    while vidcap.isOpened():\n",
    "        ID = vidcap.get(1)\n",
    "        success, image = vidcap.read()\n",
    "        \n",
    "        if success:\n",
    "            # skipping frames to avoid duplications \n",
    "            if (ID % 7 == 0):\n",
    "                flip = iaa.Fliplr(1.0)\n",
    "                zoom = iaa.Affine(scale=1.3)\n",
    "                random_brightness = iaa.Multiply((1, 1.3))\n",
    "                rotate = iaa.Affine(rotate=(-25, 25))\n",
    "                \n",
    "                image_aug = flip(image = image)\n",
    "                image_aug = random_brightness(image = image_aug)\n",
    "                image_aug = zoom(image = image_aug)\n",
    "                image_aug = rotate(image = image_aug)\n",
    "                \n",
    "                rgb_img = cv2.cvtColor(image_aug, cv2.COLOR_BGR2RGB)\n",
    "                resized = cv2.resize(rgb_img, (IMG_SIZE, IMG_SIZE))\n",
    "                ImageFrames.append(resized)\n",
    "                \n",
    "            count += 1\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    vidcap.release()\n",
    "    \n",
    "    return ImageFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have \n",
      "1000 Violence videos \n",
      "1000 NonViolence videos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [02:25<00:00,  2.06it/s]\n",
      "100%|██████████| 300/300 [02:53<00:00,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 19s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from tqdm import tqdm\n",
    "\n",
    "VideoDataDir = path\n",
    "print('we have \\n{} Violence videos \\n{} NonViolence videos'.format(\n",
    "              len(os.listdir(VideoDataDir + '\\\\Violence')), \n",
    "              len(os.listdir(VideoDataDir + '\\\\NonViolence'))))\n",
    "\n",
    "X_original = []\n",
    "y_original = []\n",
    "\n",
    "CLASSES = [\"NonViolence\", \"Violence\"]\n",
    "#600 <- 300 + 300\n",
    "\n",
    "for category in os.listdir(VideoDataDir):\n",
    "    path = os.path.join(VideoDataDir, category)\n",
    "    class_num = CLASSES.index(category)\n",
    "    for i, video in enumerate(tqdm(os.listdir(path)[0:300])):\n",
    "        frames = video_to_frames(path + '/' + video)\n",
    "        for j, frame in enumerate(frames):\n",
    "            X_original.append(frame)\n",
    "            y_original.append(class_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11948"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "X_original = np.array(X_original).reshape(-1 , IMG_SIZE * IMG_SIZE * 3)\n",
    "y_original = np.array(y_original)\n",
    "len(X_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "stratified_sample = StratifiedShuffleSplit(n_splits=2, test_size=0.3, random_state=73)\n",
    "\n",
    "for train_index, test_index in stratified_sample.split(X_original, y_original):\n",
    "    X_train, X_test = X_original[train_index], X_original[test_index]\n",
    "    y_train, y_test = y_original[train_index], y_original[test_index]\n",
    "\n",
    "X_train_nn = X_train.reshape(-1, IMG_SIZE, IMG_SIZE, 3) / 255\n",
    "X_test_nn = X_test.reshape(-1, IMG_SIZE, IMG_SIZE, 3) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.layers.core import Dropout,Flatten,Dense\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "9412608/9406464 [==============================] - 2s 0us/step\n",
      "9420800/9406464 [==============================] - 2s 0us/step\n",
      "Compiling model...\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 128, 128, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " Conv1 (Conv2D)                 (None, 64, 64, 32)   864         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " bn_Conv1 (BatchNormalization)  (None, 64, 64, 32)   128         ['Conv1[0][0]']                  \n",
      "                                                                                                  \n",
      " Conv1_relu (ReLU)              (None, 64, 64, 32)   0           ['bn_Conv1[0][0]']               \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise (Depth  (None, 64, 64, 32)  288         ['Conv1_relu[0][0]']             \n",
      " wiseConv2D)                                                                                      \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_BN (Ba  (None, 64, 64, 32)  128         ['expanded_conv_depthwise[0][0]']\n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_relu (  (None, 64, 64, 32)  0           ['expanded_conv_depthwise_BN[0][0\n",
      " ReLU)                                                           ]']                              \n",
      "                                                                                                  \n",
      " expanded_conv_project (Conv2D)  (None, 64, 64, 16)  512         ['expanded_conv_depthwise_relu[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " expanded_conv_project_BN (Batc  (None, 64, 64, 16)  64          ['expanded_conv_project[0][0]']  \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_1_expand (Conv2D)        (None, 64, 64, 96)   1536        ['expanded_conv_project_BN[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " block_1_expand_BN (BatchNormal  (None, 64, 64, 96)  384         ['block_1_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_1_expand_relu (ReLU)     (None, 64, 64, 96)   0           ['block_1_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_1_pad (ZeroPadding2D)    (None, 65, 65, 96)   0           ['block_1_expand_relu[0][0]']    \n",
      "                                                                                                  \n",
      " block_1_depthwise (DepthwiseCo  (None, 32, 32, 96)  864         ['block_1_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_1_depthwise_BN (BatchNor  (None, 32, 32, 96)  384         ['block_1_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_1_depthwise_relu (ReLU)  (None, 32, 32, 96)   0           ['block_1_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_1_project (Conv2D)       (None, 32, 32, 24)   2304        ['block_1_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_1_project_BN (BatchNorma  (None, 32, 32, 24)  96          ['block_1_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_2_expand (Conv2D)        (None, 32, 32, 144)  3456        ['block_1_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_2_expand_BN (BatchNormal  (None, 32, 32, 144)  576        ['block_2_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_2_expand_relu (ReLU)     (None, 32, 32, 144)  0           ['block_2_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_2_depthwise (DepthwiseCo  (None, 32, 32, 144)  1296       ['block_2_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_2_depthwise_BN (BatchNor  (None, 32, 32, 144)  576        ['block_2_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_2_depthwise_relu (ReLU)  (None, 32, 32, 144)  0           ['block_2_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_2_project (Conv2D)       (None, 32, 32, 24)   3456        ['block_2_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_2_project_BN (BatchNorma  (None, 32, 32, 24)  96          ['block_2_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_2_add (Add)              (None, 32, 32, 24)   0           ['block_1_project_BN[0][0]',     \n",
      "                                                                  'block_2_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_3_expand (Conv2D)        (None, 32, 32, 144)  3456        ['block_2_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_3_expand_BN (BatchNormal  (None, 32, 32, 144)  576        ['block_3_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_3_expand_relu (ReLU)     (None, 32, 32, 144)  0           ['block_3_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_3_pad (ZeroPadding2D)    (None, 33, 33, 144)  0           ['block_3_expand_relu[0][0]']    \n",
      "                                                                                                  \n",
      " block_3_depthwise (DepthwiseCo  (None, 16, 16, 144)  1296       ['block_3_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_3_depthwise_BN (BatchNor  (None, 16, 16, 144)  576        ['block_3_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_3_depthwise_relu (ReLU)  (None, 16, 16, 144)  0           ['block_3_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_3_project (Conv2D)       (None, 16, 16, 32)   4608        ['block_3_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_3_project_BN (BatchNorma  (None, 16, 16, 32)  128         ['block_3_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_4_expand (Conv2D)        (None, 16, 16, 192)  6144        ['block_3_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_4_expand_BN (BatchNormal  (None, 16, 16, 192)  768        ['block_4_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_4_expand_relu (ReLU)     (None, 16, 16, 192)  0           ['block_4_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_4_depthwise (DepthwiseCo  (None, 16, 16, 192)  1728       ['block_4_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_4_depthwise_BN (BatchNor  (None, 16, 16, 192)  768        ['block_4_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_4_depthwise_relu (ReLU)  (None, 16, 16, 192)  0           ['block_4_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_4_project (Conv2D)       (None, 16, 16, 32)   6144        ['block_4_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_4_project_BN (BatchNorma  (None, 16, 16, 32)  128         ['block_4_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_4_add (Add)              (None, 16, 16, 32)   0           ['block_3_project_BN[0][0]',     \n",
      "                                                                  'block_4_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_5_expand (Conv2D)        (None, 16, 16, 192)  6144        ['block_4_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_5_expand_BN (BatchNormal  (None, 16, 16, 192)  768        ['block_5_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_5_expand_relu (ReLU)     (None, 16, 16, 192)  0           ['block_5_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_5_depthwise (DepthwiseCo  (None, 16, 16, 192)  1728       ['block_5_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_5_depthwise_BN (BatchNor  (None, 16, 16, 192)  768        ['block_5_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_5_depthwise_relu (ReLU)  (None, 16, 16, 192)  0           ['block_5_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_5_project (Conv2D)       (None, 16, 16, 32)   6144        ['block_5_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_5_project_BN (BatchNorma  (None, 16, 16, 32)  128         ['block_5_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_5_add (Add)              (None, 16, 16, 32)   0           ['block_4_add[0][0]',            \n",
      "                                                                  'block_5_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_6_expand (Conv2D)        (None, 16, 16, 192)  6144        ['block_5_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_6_expand_BN (BatchNormal  (None, 16, 16, 192)  768        ['block_6_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_6_expand_relu (ReLU)     (None, 16, 16, 192)  0           ['block_6_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_6_pad (ZeroPadding2D)    (None, 17, 17, 192)  0           ['block_6_expand_relu[0][0]']    \n",
      "                                                                                                  \n",
      " block_6_depthwise (DepthwiseCo  (None, 8, 8, 192)   1728        ['block_6_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_6_depthwise_BN (BatchNor  (None, 8, 8, 192)   768         ['block_6_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_6_depthwise_relu (ReLU)  (None, 8, 8, 192)    0           ['block_6_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_6_project (Conv2D)       (None, 8, 8, 64)     12288       ['block_6_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_6_project_BN (BatchNorma  (None, 8, 8, 64)    256         ['block_6_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_7_expand (Conv2D)        (None, 8, 8, 384)    24576       ['block_6_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_7_expand_BN (BatchNormal  (None, 8, 8, 384)   1536        ['block_7_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_7_expand_relu (ReLU)     (None, 8, 8, 384)    0           ['block_7_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_7_depthwise (DepthwiseCo  (None, 8, 8, 384)   3456        ['block_7_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_7_depthwise_BN (BatchNor  (None, 8, 8, 384)   1536        ['block_7_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_7_depthwise_relu (ReLU)  (None, 8, 8, 384)    0           ['block_7_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_7_project (Conv2D)       (None, 8, 8, 64)     24576       ['block_7_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_7_project_BN (BatchNorma  (None, 8, 8, 64)    256         ['block_7_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_7_add (Add)              (None, 8, 8, 64)     0           ['block_6_project_BN[0][0]',     \n",
      "                                                                  'block_7_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_8_expand (Conv2D)        (None, 8, 8, 384)    24576       ['block_7_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_8_expand_BN (BatchNormal  (None, 8, 8, 384)   1536        ['block_8_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_8_expand_relu (ReLU)     (None, 8, 8, 384)    0           ['block_8_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_8_depthwise (DepthwiseCo  (None, 8, 8, 384)   3456        ['block_8_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_8_depthwise_BN (BatchNor  (None, 8, 8, 384)   1536        ['block_8_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_8_depthwise_relu (ReLU)  (None, 8, 8, 384)    0           ['block_8_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_8_project (Conv2D)       (None, 8, 8, 64)     24576       ['block_8_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_8_project_BN (BatchNorma  (None, 8, 8, 64)    256         ['block_8_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_8_add (Add)              (None, 8, 8, 64)     0           ['block_7_add[0][0]',            \n",
      "                                                                  'block_8_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_9_expand (Conv2D)        (None, 8, 8, 384)    24576       ['block_8_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_9_expand_BN (BatchNormal  (None, 8, 8, 384)   1536        ['block_9_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_9_expand_relu (ReLU)     (None, 8, 8, 384)    0           ['block_9_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_9_depthwise (DepthwiseCo  (None, 8, 8, 384)   3456        ['block_9_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_9_depthwise_BN (BatchNor  (None, 8, 8, 384)   1536        ['block_9_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_9_depthwise_relu (ReLU)  (None, 8, 8, 384)    0           ['block_9_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_9_project (Conv2D)       (None, 8, 8, 64)     24576       ['block_9_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_9_project_BN (BatchNorma  (None, 8, 8, 64)    256         ['block_9_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_9_add (Add)              (None, 8, 8, 64)     0           ['block_8_add[0][0]',            \n",
      "                                                                  'block_9_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_10_expand (Conv2D)       (None, 8, 8, 384)    24576       ['block_9_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_10_expand_BN (BatchNorma  (None, 8, 8, 384)   1536        ['block_10_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_10_expand_relu (ReLU)    (None, 8, 8, 384)    0           ['block_10_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_10_depthwise (DepthwiseC  (None, 8, 8, 384)   3456        ['block_10_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_10_depthwise_BN (BatchNo  (None, 8, 8, 384)   1536        ['block_10_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_10_depthwise_relu (ReLU)  (None, 8, 8, 384)   0           ['block_10_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_10_project (Conv2D)      (None, 8, 8, 96)     36864       ['block_10_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_10_project_BN (BatchNorm  (None, 8, 8, 96)    384         ['block_10_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_11_expand (Conv2D)       (None, 8, 8, 576)    55296       ['block_10_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_11_expand_BN (BatchNorma  (None, 8, 8, 576)   2304        ['block_11_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_11_expand_relu (ReLU)    (None, 8, 8, 576)    0           ['block_11_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_11_depthwise (DepthwiseC  (None, 8, 8, 576)   5184        ['block_11_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_11_depthwise_BN (BatchNo  (None, 8, 8, 576)   2304        ['block_11_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_11_depthwise_relu (ReLU)  (None, 8, 8, 576)   0           ['block_11_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_11_project (Conv2D)      (None, 8, 8, 96)     55296       ['block_11_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_11_project_BN (BatchNorm  (None, 8, 8, 96)    384         ['block_11_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_11_add (Add)             (None, 8, 8, 96)     0           ['block_10_project_BN[0][0]',    \n",
      "                                                                  'block_11_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_12_expand (Conv2D)       (None, 8, 8, 576)    55296       ['block_11_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_12_expand_BN (BatchNorma  (None, 8, 8, 576)   2304        ['block_12_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_12_expand_relu (ReLU)    (None, 8, 8, 576)    0           ['block_12_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_12_depthwise (DepthwiseC  (None, 8, 8, 576)   5184        ['block_12_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_12_depthwise_BN (BatchNo  (None, 8, 8, 576)   2304        ['block_12_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_12_depthwise_relu (ReLU)  (None, 8, 8, 576)   0           ['block_12_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_12_project (Conv2D)      (None, 8, 8, 96)     55296       ['block_12_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_12_project_BN (BatchNorm  (None, 8, 8, 96)    384         ['block_12_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_12_add (Add)             (None, 8, 8, 96)     0           ['block_11_add[0][0]',           \n",
      "                                                                  'block_12_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_13_expand (Conv2D)       (None, 8, 8, 576)    55296       ['block_12_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_13_expand_BN (BatchNorma  (None, 8, 8, 576)   2304        ['block_13_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_13_expand_relu (ReLU)    (None, 8, 8, 576)    0           ['block_13_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_13_pad (ZeroPadding2D)   (None, 9, 9, 576)    0           ['block_13_expand_relu[0][0]']   \n",
      "                                                                                                  \n",
      " block_13_depthwise (DepthwiseC  (None, 4, 4, 576)   5184        ['block_13_pad[0][0]']           \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_13_depthwise_BN (BatchNo  (None, 4, 4, 576)   2304        ['block_13_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_13_depthwise_relu (ReLU)  (None, 4, 4, 576)   0           ['block_13_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_13_project (Conv2D)      (None, 4, 4, 160)    92160       ['block_13_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_13_project_BN (BatchNorm  (None, 4, 4, 160)   640         ['block_13_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_14_expand (Conv2D)       (None, 4, 4, 960)    153600      ['block_13_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_14_expand_BN (BatchNorma  (None, 4, 4, 960)   3840        ['block_14_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_14_expand_relu (ReLU)    (None, 4, 4, 960)    0           ['block_14_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_14_depthwise (DepthwiseC  (None, 4, 4, 960)   8640        ['block_14_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_14_depthwise_BN (BatchNo  (None, 4, 4, 960)   3840        ['block_14_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_14_depthwise_relu (ReLU)  (None, 4, 4, 960)   0           ['block_14_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_14_project (Conv2D)      (None, 4, 4, 160)    153600      ['block_14_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_14_project_BN (BatchNorm  (None, 4, 4, 160)   640         ['block_14_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_14_add (Add)             (None, 4, 4, 160)    0           ['block_13_project_BN[0][0]',    \n",
      "                                                                  'block_14_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_15_expand (Conv2D)       (None, 4, 4, 960)    153600      ['block_14_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_15_expand_BN (BatchNorma  (None, 4, 4, 960)   3840        ['block_15_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_15_expand_relu (ReLU)    (None, 4, 4, 960)    0           ['block_15_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_15_depthwise (DepthwiseC  (None, 4, 4, 960)   8640        ['block_15_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_15_depthwise_BN (BatchNo  (None, 4, 4, 960)   3840        ['block_15_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_15_depthwise_relu (ReLU)  (None, 4, 4, 960)   0           ['block_15_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_15_project (Conv2D)      (None, 4, 4, 160)    153600      ['block_15_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_15_project_BN (BatchNorm  (None, 4, 4, 160)   640         ['block_15_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_15_add (Add)             (None, 4, 4, 160)    0           ['block_14_add[0][0]',           \n",
      "                                                                  'block_15_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_16_expand (Conv2D)       (None, 4, 4, 960)    153600      ['block_15_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_16_expand_BN (BatchNorma  (None, 4, 4, 960)   3840        ['block_16_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_16_expand_relu (ReLU)    (None, 4, 4, 960)    0           ['block_16_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_16_depthwise (DepthwiseC  (None, 4, 4, 960)   8640        ['block_16_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_16_depthwise_BN (BatchNo  (None, 4, 4, 960)   3840        ['block_16_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_16_depthwise_relu (ReLU)  (None, 4, 4, 960)   0           ['block_16_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_16_project (Conv2D)      (None, 4, 4, 320)    307200      ['block_16_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_16_project_BN (BatchNorm  (None, 4, 4, 320)   1280        ['block_16_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " Conv_1 (Conv2D)                (None, 4, 4, 1280)   409600      ['block_16_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " Conv_1_bn (BatchNormalization)  (None, 4, 4, 1280)  5120        ['Conv_1[0][0]']                 \n",
      "                                                                                                  \n",
      " out_relu (ReLU)                (None, 4, 4, 1280)   0           ['Conv_1_bn[0][0]']              \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 1280)        0           ['out_relu[0][0]']               \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1)            1281        ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,259,265\n",
      "Trainable params: 1,281\n",
      "Non-trainable params: 2,257,984\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "epochs = 150\n",
    "\n",
    "from keras import regularizers\n",
    "\n",
    "kernel_regularizer = regularizers.l2(0.0001)\n",
    "\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "\n",
    "def load_layers():\n",
    "    input_tensor = Input(shape=(IMG_SIZE, IMG_SIZE, ColorChannels))\n",
    "    baseModel = MobileNetV2(pooling='avg',\n",
    "                            include_top=False, \n",
    "                            input_tensor=input_tensor)\n",
    "    \n",
    "    headModel = baseModel.output   \n",
    "    headModel = Dense(1, activation=\"sigmoid\")(headModel)\n",
    "    model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "\n",
    "    for layer in baseModel.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    print(\"Compiling model...\")\n",
    "    model.compile(loss=\"binary_crossentropy\",\n",
    "                    optimizer='adam',\n",
    "                    metrics=[\"accuracy\"])\n",
    "\n",
    "    return model\n",
    "\n",
    "if TPU_INIT:\n",
    "    with tpu_strategy.scope():\n",
    "        model = load_layers()\n",
    "else:\n",
    "    model = load_layers()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback, ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "patience = 3\n",
    "\n",
    "start_lr = 0.00001\n",
    "min_lr = 0.00001\n",
    "max_lr = 0.00005\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "if TPU_INIT:\n",
    "    max_lr = max_lr * tpu_strategy.num_replicas_in_sync\n",
    "    batch_size = batch_size * tpu_strategy.num_replicas_in_sync\n",
    "\n",
    "rampup_epochs = 5\n",
    "sustain_epochs = 0\n",
    "exp_decay = .8\n",
    "\n",
    "def lrfn(epoch):\n",
    "    if epoch < rampup_epochs:\n",
    "        return (max_lr - start_lr)/rampup_epochs * epoch + start_lr\n",
    "    elif epoch < rampup_epochs + sustain_epochs:\n",
    "        return max_lr\n",
    "    else:\n",
    "        return (max_lr - min_lr) * exp_decay**(epoch-rampup_epochs-sustain_epochs) + min_lr\n",
    "\n",
    "\n",
    "class myCallback(Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if ((logs.get('accuracy')>=0.999)):\n",
    "            print(\"\\nLimits Reached cancelling training!\")\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_callback = myCallback()\n",
    "\n",
    "lr_callback = LearningRateScheduler(lambda epoch: lrfn(epoch), verbose=False)\n",
    "\n",
    "early_stopping = EarlyStopping(patience = patience, monitor='val_loss',\n",
    "                                 mode='min', restore_best_weights=True, \n",
    "                                 verbose = 1, min_delta = .00075)\n",
    "\n",
    "PROJECT_DIR = path + '/RiskDetection'\n",
    "\n",
    "lr_plat = ReduceLROnPlateau(patience = 2, mode = 'min')\n",
    "\n",
    "os.system('rm -rf ./logs/')\n",
    "\n",
    "import datetime\n",
    "log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir = log_dir, write_graph=True, histogram_freq=1)\n",
    "\n",
    "checkpoint_filepath = 'ModelWeights.h5'\n",
    "\n",
    "model_checkpoints = ModelCheckpoint(filepath=checkpoint_filepath,\n",
    "                                        save_weights_only=True,\n",
    "                                        monitor='val_loss',\n",
    "                                        mode='min',\n",
    "                                        verbose = 1,\n",
    "                                        save_best_only=True)\n",
    "\n",
    "\n",
    "callbacks = [end_callback, lr_callback, model_checkpoints, tensorboard_callback, early_stopping, lr_plat]\n",
    "\n",
    "if TPU_INIT:\n",
    "    callbacks = [end_callback, lr_callback, model_checkpoints, early_stopping, lr_plat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training head...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yash\\anaconda3\\envs\\open_cv\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "2091/2091 [==============================] - ETA: 0s - loss: 0.6968 - accuracy: 0.6085\n",
      "Epoch 00001: val_loss improved from inf to 0.58995, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 312s 122ms/step - loss: 0.6968 - accuracy: 0.6085 - val_loss: 0.5899 - val_accuracy: 0.6948 - lr: 1.0000e-05\n",
      "Epoch 2/150\n",
      "2090/2091 [============================>.] - ETA: 0s - loss: 0.4868 - accuracy: 0.7678\n",
      "Epoch 00002: val_loss improved from 0.58995 to 0.41824, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 155s 74ms/step - loss: 0.4868 - accuracy: 0.7679 - val_loss: 0.4182 - val_accuracy: 0.8167 - lr: 1.8000e-05\n",
      "Epoch 3/150\n",
      "2090/2091 [============================>.] - ETA: 0s - loss: 0.3525 - accuracy: 0.8577\n",
      "Epoch 00003: val_loss improved from 0.41824 to 0.31867, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 144s 69ms/step - loss: 0.3528 - accuracy: 0.8576 - val_loss: 0.3187 - val_accuracy: 0.8706 - lr: 2.6000e-05\n",
      "Epoch 4/150\n",
      "2090/2091 [============================>.] - ETA: 0s - loss: 0.2757 - accuracy: 0.8957\n",
      "Epoch 00004: val_loss improved from 0.31867 to 0.26078, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 154s 74ms/step - loss: 0.2759 - accuracy: 0.8956 - val_loss: 0.2608 - val_accuracy: 0.8976 - lr: 3.4000e-05\n",
      "Epoch 5/150\n",
      "2091/2091 [==============================] - ETA: 0s - loss: 0.2288 - accuracy: 0.9141\n",
      "Epoch 00005: val_loss improved from 0.26078 to 0.22402, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 150s 72ms/step - loss: 0.2288 - accuracy: 0.9141 - val_loss: 0.2240 - val_accuracy: 0.9169 - lr: 4.2000e-05\n",
      "Epoch 6/150\n",
      "2091/2091 [==============================] - ETA: 0s - loss: 0.1969 - accuracy: 0.9262\n",
      "Epoch 00006: val_loss improved from 0.22402 to 0.19926, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 148s 71ms/step - loss: 0.1969 - accuracy: 0.9262 - val_loss: 0.1993 - val_accuracy: 0.9269 - lr: 5.0000e-05\n",
      "Epoch 7/150\n",
      "2091/2091 [==============================] - ETA: 0s - loss: 0.1765 - accuracy: 0.9350\n",
      "Epoch 00007: val_loss improved from 0.19926 to 0.18570, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 140s 67ms/step - loss: 0.1765 - accuracy: 0.9350 - val_loss: 0.1857 - val_accuracy: 0.9331 - lr: 4.2000e-05\n",
      "Epoch 8/150\n",
      "2090/2091 [============================>.] - ETA: 0s - loss: 0.1633 - accuracy: 0.9385\n",
      "Epoch 00008: val_loss improved from 0.18570 to 0.17675, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 137s 66ms/step - loss: 0.1633 - accuracy: 0.9385 - val_loss: 0.1768 - val_accuracy: 0.9384 - lr: 3.5600e-05\n",
      "Epoch 9/150\n",
      "2090/2091 [============================>.] - ETA: 0s - loss: 0.1551 - accuracy: 0.9427\n",
      "Epoch 00009: val_loss improved from 0.17675 to 0.17074, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 131s 62ms/step - loss: 0.1551 - accuracy: 0.9427 - val_loss: 0.1707 - val_accuracy: 0.9403 - lr: 3.0480e-05\n",
      "Epoch 10/150\n",
      "2090/2091 [============================>.] - ETA: 0s - loss: 0.1484 - accuracy: 0.9445\n",
      "Epoch 00010: val_loss improved from 0.17074 to 0.16698, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 126s 60ms/step - loss: 0.1483 - accuracy: 0.9445 - val_loss: 0.1670 - val_accuracy: 0.9406 - lr: 2.6384e-05\n",
      "Epoch 11/150\n",
      "2090/2091 [============================>.] - ETA: 0s - loss: 0.1435 - accuracy: 0.9461\n",
      "Epoch 00011: val_loss improved from 0.16698 to 0.16221, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 128s 61ms/step - loss: 0.1435 - accuracy: 0.9461 - val_loss: 0.1622 - val_accuracy: 0.9414 - lr: 2.3107e-05\n",
      "Epoch 12/150\n",
      "2091/2091 [==============================] - ETA: 0s - loss: 0.1394 - accuracy: 0.9469\n",
      "Epoch 00012: val_loss improved from 0.16221 to 0.15887, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 133s 63ms/step - loss: 0.1394 - accuracy: 0.9469 - val_loss: 0.1589 - val_accuracy: 0.9417 - lr: 2.0486e-05\n",
      "Epoch 13/150\n",
      "2090/2091 [============================>.] - ETA: 0s - loss: 0.1361 - accuracy: 0.9492\n",
      "Epoch 00013: val_loss improved from 0.15887 to 0.15671, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 137s 66ms/step - loss: 0.1361 - accuracy: 0.9492 - val_loss: 0.1567 - val_accuracy: 0.9414 - lr: 1.8389e-05\n",
      "Epoch 14/150\n",
      "2090/2091 [============================>.] - ETA: 0s - loss: 0.1336 - accuracy: 0.9498\n",
      "Epoch 00014: val_loss improved from 0.15671 to 0.15458, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 154s 74ms/step - loss: 0.1335 - accuracy: 0.9498 - val_loss: 0.1546 - val_accuracy: 0.9431 - lr: 1.6711e-05\n",
      "Epoch 15/150\n",
      "2090/2091 [============================>.] - ETA: 0s - loss: 0.1310 - accuracy: 0.9512\n",
      "Epoch 00015: val_loss improved from 0.15458 to 0.15353, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 144s 69ms/step - loss: 0.1310 - accuracy: 0.9512 - val_loss: 0.1535 - val_accuracy: 0.9434 - lr: 1.5369e-05\n",
      "Epoch 16/150\n",
      "2090/2091 [============================>.] - ETA: 0s - loss: 0.1290 - accuracy: 0.9513\n",
      "Epoch 00016: val_loss improved from 0.15353 to 0.15136, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 155s 74ms/step - loss: 0.1290 - accuracy: 0.9513 - val_loss: 0.1514 - val_accuracy: 0.9439 - lr: 1.4295e-05\n",
      "Epoch 17/150\n",
      "2090/2091 [============================>.] - ETA: 0s - loss: 0.1273 - accuracy: 0.9520\n",
      "Epoch 00017: val_loss improved from 0.15136 to 0.14974, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 164s 79ms/step - loss: 0.1272 - accuracy: 0.9521 - val_loss: 0.1497 - val_accuracy: 0.9448 - lr: 1.3436e-05\n",
      "Epoch 18/150\n",
      "2090/2091 [============================>.] - ETA: 0s - loss: 0.1256 - accuracy: 0.9520\n",
      "Epoch 00018: val_loss improved from 0.14974 to 0.14844, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 152s 73ms/step - loss: 0.1256 - accuracy: 0.9521 - val_loss: 0.1484 - val_accuracy: 0.9453 - lr: 1.2749e-05\n",
      "Epoch 19/150\n",
      "2090/2091 [============================>.] - ETA: 0s - loss: 0.1241 - accuracy: 0.9526\n",
      "Epoch 00019: val_loss improved from 0.14844 to 0.14719, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 129s 62ms/step - loss: 0.1241 - accuracy: 0.9526 - val_loss: 0.1472 - val_accuracy: 0.9456 - lr: 1.2199e-05\n",
      "Epoch 20/150\n",
      "2090/2091 [============================>.] - ETA: 0s - loss: 0.1223 - accuracy: 0.9542 ETA: 0s - loss: 0.122\n",
      "Epoch 00020: val_loss improved from 0.14719 to 0.14681, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 135s 65ms/step - loss: 0.1226 - accuracy: 0.9541 - val_loss: 0.1468 - val_accuracy: 0.9450 - lr: 1.1759e-05\n",
      "Epoch 21/150\n",
      "2090/2091 [============================>.] - ETA: 0s - loss: 0.1214 - accuracy: 0.9547\n",
      "Epoch 00021: val_loss improved from 0.14681 to 0.14510, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 148s 71ms/step - loss: 0.1214 - accuracy: 0.9547 - val_loss: 0.1451 - val_accuracy: 0.9464 - lr: 1.1407e-05\n",
      "Epoch 22/150\n",
      "2090/2091 [============================>.] - ETA: 0s - loss: 0.1201 - accuracy: 0.9551\n",
      "Epoch 00022: val_loss improved from 0.14510 to 0.14441, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 151s 72ms/step - loss: 0.1201 - accuracy: 0.9552 - val_loss: 0.1444 - val_accuracy: 0.9470 - lr: 1.1126e-05\n",
      "Epoch 23/150\n",
      "2090/2091 [============================>.] - ETA: 0s - loss: 0.1191 - accuracy: 0.9553\n",
      "Epoch 00023: val_loss improved from 0.14441 to 0.14319, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 154s 74ms/step - loss: 0.1191 - accuracy: 0.9553 - val_loss: 0.1432 - val_accuracy: 0.9470 - lr: 1.0901e-05\n",
      "Epoch 24/150\n",
      "2091/2091 [==============================] - ETA: 0s - loss: 0.1179 - accuracy: 0.9550\n",
      "Epoch 00024: val_loss improved from 0.14319 to 0.14232, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 149s 71ms/step - loss: 0.1179 - accuracy: 0.9550 - val_loss: 0.1423 - val_accuracy: 0.9473 - lr: 1.0721e-05\n",
      "Epoch 25/150\n",
      "2090/2091 [============================>.] - ETA: 0s - loss: 0.1170 - accuracy: 0.9571\n",
      "Epoch 00025: val_loss improved from 0.14232 to 0.14159, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 149s 71ms/step - loss: 0.1169 - accuracy: 0.9571 - val_loss: 0.1416 - val_accuracy: 0.9476 - lr: 1.0576e-05\n",
      "Epoch 26/150\n",
      "2090/2091 [============================>.] - ETA: 0s - loss: 0.1159 - accuracy: 0.9571\n",
      "Epoch 00026: val_loss improved from 0.14159 to 0.14076, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 148s 71ms/step - loss: 0.1159 - accuracy: 0.9571 - val_loss: 0.1408 - val_accuracy: 0.9481 - lr: 1.0461e-05\n",
      "Epoch 27/150\n",
      "2091/2091 [==============================] - ETA: 0s - loss: 0.1150 - accuracy: 0.9573\n",
      "Epoch 00027: val_loss improved from 0.14076 to 0.14004, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 131s 63ms/step - loss: 0.1150 - accuracy: 0.9573 - val_loss: 0.1400 - val_accuracy: 0.9481 - lr: 1.0369e-05\n",
      "Epoch 28/150\n",
      "2090/2091 [============================>.] - ETA: 0s - loss: 0.1140 - accuracy: 0.9580\n",
      "Epoch 00028: val_loss improved from 0.14004 to 0.13920, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 136s 65ms/step - loss: 0.1141 - accuracy: 0.9579 - val_loss: 0.1392 - val_accuracy: 0.9492 - lr: 1.0295e-05\n",
      "Epoch 29/150\n",
      "2090/2091 [============================>.] - ETA: 0s - loss: 0.1132 - accuracy: 0.9591 ETA: 0s - loss: 0.1131 - accuracy: 0. - ETA: 0s - loss: 0.1\n",
      "Epoch 00029: val_loss improved from 0.13920 to 0.13862, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 139s 67ms/step - loss: 0.1131 - accuracy: 0.9591 - val_loss: 0.1386 - val_accuracy: 0.9495 - lr: 1.0236e-05\n",
      "Epoch 30/150\n",
      "2091/2091 [==============================] - ETA: 0s - loss: 0.1121 - accuracy: 0.9595\n",
      "Epoch 00030: val_loss improved from 0.13862 to 0.13844, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 133s 63ms/step - loss: 0.1121 - accuracy: 0.9595 - val_loss: 0.1384 - val_accuracy: 0.9478 - lr: 1.0189e-05\n",
      "Epoch 31/150\n",
      "2091/2091 [==============================] - ETA: 0s - loss: 0.1114 - accuracy: 0.9592 ETA: 0s - loss: 0.111\n",
      "Epoch 00031: val_loss improved from 0.13844 to 0.13762, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 130s 62ms/step - loss: 0.1114 - accuracy: 0.9592 - val_loss: 0.1376 - val_accuracy: 0.9481 - lr: 1.0151e-05\n",
      "Epoch 32/150\n",
      "2091/2091 [==============================] - ETA: 0s - loss: 0.1105 - accuracy: 0.9602\n",
      "Epoch 00032: val_loss improved from 0.13762 to 0.13648, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 117s 56ms/step - loss: 0.1105 - accuracy: 0.9602 - val_loss: 0.1365 - val_accuracy: 0.9501 - lr: 1.0121e-05\n",
      "Epoch 33/150\n",
      "2091/2091 [==============================] - ETA: 0s - loss: 0.1097 - accuracy: 0.9602\n",
      "Epoch 00033: val_loss improved from 0.13648 to 0.13593, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 126s 60ms/step - loss: 0.1097 - accuracy: 0.9602 - val_loss: 0.1359 - val_accuracy: 0.9515 - lr: 1.0097e-05\n",
      "Epoch 34/150\n",
      "2091/2091 [==============================] - ETA: 0s - loss: 0.1091 - accuracy: 0.9608\n",
      "Epoch 00034: val_loss improved from 0.13593 to 0.13524, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 143s 68ms/step - loss: 0.1091 - accuracy: 0.9608 - val_loss: 0.1352 - val_accuracy: 0.9517 - lr: 1.0077e-05\n",
      "Epoch 35/150\n",
      "2090/2091 [============================>.] - ETA: 0s - loss: 0.1081 - accuracy: 0.9608\n",
      "Epoch 00035: val_loss improved from 0.13524 to 0.13481, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 136s 65ms/step - loss: 0.1082 - accuracy: 0.9607 - val_loss: 0.1348 - val_accuracy: 0.9509 - lr: 1.0062e-05\n",
      "Epoch 36/150\n",
      "2090/2091 [============================>.] - ETA: 0s - loss: 0.1075 - accuracy: 0.9611\n",
      "Epoch 00036: val_loss improved from 0.13481 to 0.13431, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 116s 55ms/step - loss: 0.1075 - accuracy: 0.9611 - val_loss: 0.1343 - val_accuracy: 0.9503 - lr: 1.0050e-05\n",
      "Epoch 37/150\n",
      "2090/2091 [============================>.] - ETA: 0s - loss: 0.1067 - accuracy: 0.9616\n",
      "Epoch 00037: val_loss improved from 0.13431 to 0.13404, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 135s 65ms/step - loss: 0.1067 - accuracy: 0.9616 - val_loss: 0.1340 - val_accuracy: 0.9498 - lr: 1.0040e-05\n",
      "Epoch 38/150\n",
      "2091/2091 [==============================] - ETA: 0s - loss: 0.1060 - accuracy: 0.9617\n",
      "Epoch 00038: val_loss improved from 0.13404 to 0.13292, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 135s 64ms/step - loss: 0.1060 - accuracy: 0.9617 - val_loss: 0.1329 - val_accuracy: 0.9520 - lr: 1.0032e-05\n",
      "Epoch 39/150\n",
      "2090/2091 [============================>.] - ETA: 0s - loss: 0.1054 - accuracy: 0.96 - ETA: 0s - loss: 0.1053 - accuracy: 0.9624\n",
      "Epoch 00039: val_loss improved from 0.13292 to 0.13262, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 130s 62ms/step - loss: 0.1053 - accuracy: 0.9625 - val_loss: 0.1326 - val_accuracy: 0.9509 - lr: 1.0025e-05\n",
      "Epoch 40/150\n",
      "2091/2091 [==============================] - ETA: 0s - loss: 0.1046 - accuracy: 0.9628\n",
      "Epoch 00040: val_loss improved from 0.13262 to 0.13195, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 131s 63ms/step - loss: 0.1046 - accuracy: 0.9628 - val_loss: 0.1319 - val_accuracy: 0.9517 - lr: 1.0020e-05\n",
      "Epoch 41/150\n",
      "2090/2091 [============================>.] - ETA: 0s - loss: 0.1040 - accuracy: 0.9620\n",
      "Epoch 00041: val_loss improved from 0.13195 to 0.13137, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 143s 68ms/step - loss: 0.1040 - accuracy: 0.9620 - val_loss: 0.1314 - val_accuracy: 0.9523 - lr: 1.0016e-05\n",
      "Epoch 42/150\n",
      "2091/2091 [==============================] - ETA: 0s - loss: 0.1032 - accuracy: 0.9631\n",
      "Epoch 00042: val_loss improved from 0.13137 to 0.13081, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 135s 64ms/step - loss: 0.1032 - accuracy: 0.9631 - val_loss: 0.1308 - val_accuracy: 0.9520 - lr: 1.0013e-05\n",
      "Epoch 43/150\n",
      "2091/2091 [==============================] - ETA: 0s - loss: 0.1026 - accuracy: 0.9627\n",
      "Epoch 00043: val_loss improved from 0.13081 to 0.13027, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 177s 85ms/step - loss: 0.1026 - accuracy: 0.9627 - val_loss: 0.1303 - val_accuracy: 0.9515 - lr: 1.0010e-05\n",
      "Epoch 44/150\n",
      "2091/2091 [==============================] - ETA: 0s - loss: 0.1019 - accuracy: 0.9634\n",
      "Epoch 00044: val_loss improved from 0.13027 to 0.12998, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 139s 66ms/step - loss: 0.1019 - accuracy: 0.9634 - val_loss: 0.1300 - val_accuracy: 0.9515 - lr: 1.0008e-05\n",
      "Epoch 45/150\n",
      "2090/2091 [============================>.] - ETA: 0s - loss: 0.1014 - accuracy: 0.9640\n",
      "Epoch 00045: val_loss improved from 0.12998 to 0.12944, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 119s 57ms/step - loss: 0.1014 - accuracy: 0.9640 - val_loss: 0.1294 - val_accuracy: 0.9515 - lr: 1.0007e-05\n",
      "Epoch 46/150\n",
      "2090/2091 [============================>.] - ETA: 0s - loss: 0.1006 - accuracy: 0.9633\n",
      "Epoch 00046: val_loss improved from 0.12944 to 0.12943, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 123s 59ms/step - loss: 0.1006 - accuracy: 0.9632 - val_loss: 0.1294 - val_accuracy: 0.9509 - lr: 1.0005e-05\n",
      "Epoch 47/150\n",
      "2091/2091 [==============================] - ETA: 0s - loss: 0.1001 - accuracy: 0.9642\n",
      "Epoch 00047: val_loss improved from 0.12943 to 0.12839, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 123s 59ms/step - loss: 0.1001 - accuracy: 0.9642 - val_loss: 0.1284 - val_accuracy: 0.9526 - lr: 1.0004e-05\n",
      "Epoch 48/150\n",
      "2090/2091 [============================>.] - ETA: 0s - loss: 0.0995 - accuracy: 0.9650\n",
      "Epoch 00048: val_loss improved from 0.12839 to 0.12793, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 133s 64ms/step - loss: 0.0996 - accuracy: 0.9650 - val_loss: 0.1279 - val_accuracy: 0.9526 - lr: 1.0003e-05\n",
      "Epoch 49/150\n",
      "2090/2091 [============================>.] - ETA: 0s - loss: 0.0990 - accuracy: 0.9651\n",
      "Epoch 00049: val_loss improved from 0.12793 to 0.12765, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 125s 60ms/step - loss: 0.0990 - accuracy: 0.9651 - val_loss: 0.1277 - val_accuracy: 0.9520 - lr: 1.0003e-05\n",
      "Epoch 50/150\n",
      "2091/2091 [==============================] - ETA: 0s - loss: 0.0983 - accuracy: 0.9648\n",
      "Epoch 00050: val_loss improved from 0.12765 to 0.12744, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 123s 59ms/step - loss: 0.0983 - accuracy: 0.9648 - val_loss: 0.1274 - val_accuracy: 0.9515 - lr: 1.0002e-05\n",
      "Epoch 51/150\n",
      "2091/2091 [==============================] - ETA: 0s - loss: 0.0979 - accuracy: 0.9647\n",
      "Epoch 00051: val_loss improved from 0.12744 to 0.12684, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 126s 60ms/step - loss: 0.0979 - accuracy: 0.9647 - val_loss: 0.1268 - val_accuracy: 0.9523 - lr: 1.0002e-05\n",
      "Epoch 52/150\n",
      "2091/2091 [==============================] - ETA: 0s - loss: 0.0972 - accuracy: 0.9648 ETA: 0s - loss: 0.0970 - \n",
      "Epoch 00052: val_loss improved from 0.12684 to 0.12620, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 176s 84ms/step - loss: 0.0972 - accuracy: 0.9648 - val_loss: 0.1262 - val_accuracy: 0.9537 - lr: 1.0001e-05\n",
      "Epoch 53/150\n",
      "2090/2091 [============================>.] - ETA: 0s - loss: 0.0968 - accuracy: 0.9659\n",
      "Epoch 00053: val_loss improved from 0.12620 to 0.12574, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 143s 68ms/step - loss: 0.0967 - accuracy: 0.9659 - val_loss: 0.1257 - val_accuracy: 0.9540 - lr: 1.0001e-05\n",
      "Epoch 54/150\n",
      "2091/2091 [==============================] - ETA: 0s - loss: 0.0962 - accuracy: 0.9658\n",
      "Epoch 00054: val_loss improved from 0.12574 to 0.12534, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 147s 70ms/step - loss: 0.0962 - accuracy: 0.9658 - val_loss: 0.1253 - val_accuracy: 0.9537 - lr: 1.0001e-05\n",
      "Epoch 55/150\n",
      "2090/2091 [============================>.] - ETA: 0s - loss: 0.0957 - accuracy: 0.9661\n",
      "Epoch 00055: val_loss improved from 0.12534 to 0.12501, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 146s 70ms/step - loss: 0.0956 - accuracy: 0.9662 - val_loss: 0.1250 - val_accuracy: 0.9534 - lr: 1.0001e-05\n",
      "Epoch 56/150\n",
      "2091/2091 [==============================] - ETA: 0s - loss: 0.0951 - accuracy: 0.9660\n",
      "Epoch 00056: val_loss improved from 0.12501 to 0.12495, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 154s 74ms/step - loss: 0.0951 - accuracy: 0.9660 - val_loss: 0.1250 - val_accuracy: 0.9526 - lr: 1.0001e-05\n",
      "Epoch 57/150\n",
      "2090/2091 [============================>.] - ETA: 0s - loss: 0.0945 - accuracy: 0.9665\n",
      "Epoch 00057: val_loss improved from 0.12495 to 0.12424, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 142s 68ms/step - loss: 0.0945 - accuracy: 0.9665 - val_loss: 0.1242 - val_accuracy: 0.9534 - lr: 1.0000e-05\n",
      "Epoch 58/150\n",
      "2090/2091 [============================>.] - ETA: 0s - loss: 0.0941 - accuracy: 0.9664\n",
      "Epoch 00058: val_loss improved from 0.12424 to 0.12399, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 148s 71ms/step - loss: 0.0941 - accuracy: 0.9664 - val_loss: 0.1240 - val_accuracy: 0.9531 - lr: 1.0000e-05\n",
      "Epoch 59/150\n",
      "2090/2091 [============================>.] - ETA: 0s - loss: 0.0937 - accuracy: 0.9667 ETA: 0s - loss: 0.0937 - ac\n",
      "Epoch 00059: val_loss improved from 0.12399 to 0.12353, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 147s 70ms/step - loss: 0.0937 - accuracy: 0.9668 - val_loss: 0.1235 - val_accuracy: 0.9540 - lr: 1.0000e-05\n",
      "Epoch 60/150\n",
      "2091/2091 [==============================] - ETA: 0s - loss: 0.0931 - accuracy: 0.9678\n",
      "Epoch 00060: val_loss improved from 0.12353 to 0.12308, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 148s 71ms/step - loss: 0.0931 - accuracy: 0.9678 - val_loss: 0.1231 - val_accuracy: 0.9545 - lr: 1.0000e-05\n",
      "Epoch 61/150\n",
      "2090/2091 [============================>.] - ETA: 0s - loss: 0.0924 - accuracy: 0.9684\n",
      "Epoch 00061: val_loss did not improve from 0.12308\n",
      "2091/2091 [==============================] - 147s 70ms/step - loss: 0.0924 - accuracy: 0.9684 - val_loss: 0.1237 - val_accuracy: 0.9526 - lr: 1.0000e-05\n",
      "Epoch 62/150\n",
      "2091/2091 [==============================] - ETA: 0s - loss: 0.0923 - accuracy: 0.9684\n",
      "Epoch 00062: val_loss improved from 0.12308 to 0.12246, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 150s 72ms/step - loss: 0.0923 - accuracy: 0.9684 - val_loss: 0.1225 - val_accuracy: 0.9537 - lr: 1.0000e-05\n",
      "Epoch 63/150\n",
      "2090/2091 [============================>.] - ETA: 0s - loss: 0.0917 - accuracy: 0.9679\n",
      "Epoch 00063: val_loss improved from 0.12246 to 0.12197, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 132s 63ms/step - loss: 0.0917 - accuracy: 0.9680 - val_loss: 0.1220 - val_accuracy: 0.9556 - lr: 1.0000e-05\n",
      "Epoch 64/150\n",
      "2091/2091 [==============================] - ETA: 0s - loss: 0.0913 - accuracy: 0.9686 ETA: 1s -\n",
      "Epoch 00064: val_loss improved from 0.12197 to 0.12172, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 193s 92ms/step - loss: 0.0913 - accuracy: 0.9686 - val_loss: 0.1217 - val_accuracy: 0.9540 - lr: 1.0000e-05\n",
      "Epoch 65/150\n",
      "2091/2091 [==============================] - ETA: 0s - loss: 0.0908 - accuracy: 0.9684\n",
      "Epoch 00065: val_loss improved from 0.12172 to 0.12127, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 247s 118ms/step - loss: 0.0908 - accuracy: 0.9684 - val_loss: 0.1213 - val_accuracy: 0.9556 - lr: 1.0000e-05\n",
      "Epoch 66/150\n",
      "2091/2091 [==============================] - ETA: 0s - loss: 0.0904 - accuracy: 0.9694\n",
      "Epoch 00066: val_loss improved from 0.12127 to 0.12098, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 276s 132ms/step - loss: 0.0904 - accuracy: 0.9694 - val_loss: 0.1210 - val_accuracy: 0.9554 - lr: 1.0000e-05\n",
      "Epoch 67/150\n",
      "2091/2091 [==============================] - ETA: 0s - loss: 0.0899 - accuracy: 0.9694 ETA: 0s - loss: 0.0898 - accura\n",
      "Epoch 00067: val_loss improved from 0.12098 to 0.12081, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 150s 72ms/step - loss: 0.0899 - accuracy: 0.9694 - val_loss: 0.1208 - val_accuracy: 0.9545 - lr: 1.0000e-05\n",
      "Epoch 68/150\n",
      "2091/2091 [==============================] - ETA: 0s - loss: 0.0895 - accuracy: 0.9696\n",
      "Epoch 00068: val_loss improved from 0.12081 to 0.12047, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 151s 72ms/step - loss: 0.0895 - accuracy: 0.9696 - val_loss: 0.1205 - val_accuracy: 0.9551 - lr: 1.0000e-05\n",
      "Epoch 69/150\n",
      "2090/2091 [============================>.] - ETA: 0s - loss: 0.0890 - accuracy: 0.9695\n",
      "Epoch 00069: val_loss improved from 0.12047 to 0.12003, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 148s 71ms/step - loss: 0.0890 - accuracy: 0.9695 - val_loss: 0.1200 - val_accuracy: 0.9554 - lr: 1.0000e-05\n",
      "Epoch 70/150\n",
      "2091/2091 [==============================] - ETA: 0s - loss: 0.0887 - accuracy: 0.9696\n",
      "Epoch 00070: val_loss improved from 0.12003 to 0.11979, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 150s 72ms/step - loss: 0.0887 - accuracy: 0.9696 - val_loss: 0.1198 - val_accuracy: 0.9551 - lr: 1.0000e-05\n",
      "Epoch 71/150\n",
      "2090/2091 [============================>.] - ETA: 0s - loss: 0.0882 - accuracy: 0.9703\n",
      "Epoch 00071: val_loss improved from 0.11979 to 0.11939, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 150s 72ms/step - loss: 0.0882 - accuracy: 0.9703 - val_loss: 0.1194 - val_accuracy: 0.9554 - lr: 1.0000e-05\n",
      "Epoch 72/150\n",
      "2090/2091 [============================>.] - ETA: 0s - loss: 0.0878 - accuracy: 0.9707\n",
      "Epoch 00072: val_loss improved from 0.11939 to 0.11909, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 153s 73ms/step - loss: 0.0878 - accuracy: 0.9707 - val_loss: 0.1191 - val_accuracy: 0.9554 - lr: 1.0000e-05\n",
      "Epoch 73/150\n",
      "2091/2091 [==============================] - ETA: 0s - loss: 0.0872 - accuracy: 0.9712 ETA: 0s - loss: 0\n",
      "Epoch 00073: val_loss improved from 0.11909 to 0.11887, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 153s 73ms/step - loss: 0.0872 - accuracy: 0.9712 - val_loss: 0.1189 - val_accuracy: 0.9562 - lr: 1.0000e-05\n",
      "Epoch 74/150\n",
      "2090/2091 [============================>.] - ETA: 0s - loss: 0.0870 - accuracy: 0.9708\n",
      "Epoch 00074: val_loss improved from 0.11887 to 0.11851, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 151s 72ms/step - loss: 0.0870 - accuracy: 0.9708 - val_loss: 0.1185 - val_accuracy: 0.9554 - lr: 1.0000e-05\n",
      "Epoch 75/150\n",
      "2090/2091 [============================>.] - ETA: 0s - loss: 0.0866 - accuracy: 0.9709\n",
      "Epoch 00075: val_loss improved from 0.11851 to 0.11826, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 148s 71ms/step - loss: 0.0866 - accuracy: 0.9709 - val_loss: 0.1183 - val_accuracy: 0.9554 - lr: 1.0000e-05\n",
      "Epoch 76/150\n",
      "2090/2091 [============================>.] - ETA: 0s - loss: 0.0861 - accuracy: 0.9712\n",
      "Epoch 00076: val_loss improved from 0.11826 to 0.11795, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 149s 71ms/step - loss: 0.0861 - accuracy: 0.9712 - val_loss: 0.1180 - val_accuracy: 0.9565 - lr: 1.0000e-05\n",
      "Epoch 77/150\n",
      "2090/2091 [============================>.] - ETA: 0s - loss: 0.0858 - accuracy: 0.9712\n",
      "Epoch 00077: val_loss improved from 0.11795 to 0.11762, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 151s 72ms/step - loss: 0.0858 - accuracy: 0.9712 - val_loss: 0.1176 - val_accuracy: 0.9562 - lr: 1.0000e-05\n",
      "Epoch 78/150\n",
      "2090/2091 [============================>.] - ETA: 0s - loss: 0.0854 - accuracy: 0.9712\n",
      "Epoch 00078: val_loss improved from 0.11762 to 0.11737, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 146s 70ms/step - loss: 0.0854 - accuracy: 0.9712 - val_loss: 0.1174 - val_accuracy: 0.9565 - lr: 1.0000e-05\n",
      "Epoch 79/150\n",
      "2091/2091 [==============================] - ETA: 0s - loss: 0.0850 - accuracy: 0.9714\n",
      "Epoch 00079: val_loss improved from 0.11737 to 0.11707, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 153s 73ms/step - loss: 0.0850 - accuracy: 0.9714 - val_loss: 0.1171 - val_accuracy: 0.9565 - lr: 1.0000e-05\n",
      "Epoch 80/150\n",
      "2090/2091 [============================>.] - ETA: 0s - loss: 0.0846 - accuracy: 0.9722\n",
      "Epoch 00080: val_loss improved from 0.11707 to 0.11689, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 151s 72ms/step - loss: 0.0846 - accuracy: 0.9723 - val_loss: 0.1169 - val_accuracy: 0.9559 - lr: 1.0000e-05\n",
      "Epoch 81/150\n",
      "2091/2091 [==============================] - ETA: 0s - loss: 0.0843 - accuracy: 0.9715\n",
      "Epoch 00081: val_loss improved from 0.11689 to 0.11656, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 139s 67ms/step - loss: 0.0843 - accuracy: 0.9715 - val_loss: 0.1166 - val_accuracy: 0.9559 - lr: 1.0000e-05\n",
      "Epoch 82/150\n",
      "2090/2091 [============================>.] - ETA: 0s - loss: 0.0839 - accuracy: 0.9724\n",
      "Epoch 00082: val_loss improved from 0.11656 to 0.11643, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 138s 66ms/step - loss: 0.0839 - accuracy: 0.9724 - val_loss: 0.1164 - val_accuracy: 0.9565 - lr: 1.0000e-05\n",
      "Epoch 83/150\n",
      "2090/2091 [============================>.] - ETA: 0s - loss: 0.0835 - accuracy: 0.9727\n",
      "Epoch 00083: val_loss improved from 0.11643 to 0.11615, saving model to ModelWeights.h5\n",
      "2091/2091 [==============================] - 137s 65ms/step - loss: 0.0835 - accuracy: 0.9726 - val_loss: 0.1161 - val_accuracy: 0.9565 - lr: 1.0000e-05\n",
      "Epoch 84/150\n",
      "2090/2091 [============================>.] - ETA: 0s - loss: 0.0832 - accuracy: 0.9722\n",
      "Epoch 00084: val_loss improved from 0.11615 to 0.11582, saving model to ModelWeights.h5\n",
      "Restoring model weights from the end of the best epoch: 81.\n",
      "2091/2091 [==============================] - 132s 63ms/step - loss: 0.0832 - accuracy: 0.9723 - val_loss: 0.1158 - val_accuracy: 0.9565 - lr: 1.0000e-05\n",
      "Epoch 00084: early stopping\n",
      "\n",
      "Restoring best Weights for MobileNetV2\n"
     ]
    }
   ],
   "source": [
    "print('Training head...')\n",
    "#model.load_weights('./Model_Weights.h5')\n",
    "\n",
    "history = model.fit(X_train_nn ,y_train, epochs=epochs,callbacks=callbacks,validation_data = (X_test_nn, y_test),batch_size=batch_size)\n",
    "\n",
    "print('\\nRestoring best Weights for MobileNetV2')\n",
    "model.load_weights(checkpoint_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "def print_graph(item, index, history):\n",
    "    plt.figure()\n",
    "    train_values = history.history[item][0:index]\n",
    "    plt.plot(train_values)\n",
    "    test_values = history.history['val_' + item][0:index]\n",
    "    plt.plot(test_values)\n",
    "    plt.legend(['training','validation'])\n",
    "    plt.title('Training and validation '+ item)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.show()\n",
    "    plot = '{}.png'.format(item)\n",
    "    plt.savefig(plot)\n",
    "\n",
    "\n",
    "def get_best_epoch(test_loss, history):\n",
    "    for key, item in enumerate(history.history.items()):\n",
    "        (name, arr) = item\n",
    "        if name == 'val_loss':\n",
    "            for i in range(len(arr)):\n",
    "                if round(test_loss, 2) == round(arr[i], 2):\n",
    "                    return i\n",
    "                \n",
    "def model_summary(model, history):\n",
    "    print('---'*30)\n",
    "    test_loss, test_accuracy = model.evaluate(X_test_nn, y_test, verbose=0)\n",
    "\n",
    "    if history:\n",
    "        index = get_best_epoch(test_loss, history)\n",
    "        print('Best Epochs: ', index)\n",
    "\n",
    "        train_accuracy = history.history['accuracy'][index]\n",
    "        train_loss = history.history['loss'][index]\n",
    "\n",
    "        print('Accuracy on train:',train_accuracy,'\\tLoss on train:',train_loss)\n",
    "        print('Accuracy on test:',test_accuracy,'\\tLoss on test:',test_loss)\n",
    "        print_graph('loss', index, history)\n",
    "        print_graph('accuracy', index, history)\n",
    "        print('---'*30)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------\n",
      "Best Epochs:  55\n",
      "Accuracy on train: 0.9660409092903137 \tLoss on train: 0.09508222341537476\n",
      "Accuracy on test: 0.9564853310585022 \tLoss on test: 0.11581676453351974\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEWCAYAAAB2X2wCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAxLklEQVR4nO3deZxU9Zno/89TW3dXd9MLNGs3iwrKogI2qFETjEswibgkKsbkxswY7zg6xkkmM5h7R403+d0kkzFmbjSJGnMzGY0SognjYDQqbnPVYRVBMCCyNNDQNL1vtT2/P86p7qLppWiqu6iq5/161essderUc4rm+X7P93zP94iqYowxJvN50h2AMcaY1LCEbowxWcISujHGZAlL6MYYkyUsoRtjTJawhG6MMVnCErrpk4g8LyJfTvW26SQiu0Tk0mHYr4rIae78z0TkH5PZdgjfc5OIvDjUOAfY7yIRqUn1fs3I86U7AJM6ItKasBgEuoCou/zfVfWJZPelqlcMx7bZTlX/KhX7EZGpwEeAX1Uj7r6fAJL+NzS5xxJ6FlHVovi8iOwCblHVl3pvJyK+eJIwxmQPa3LJAfFTahH5BxGpBX4pImUi8pyI1IlIgztfmfCZV0XkFnf+ZhF5U0R+6G77kYhcMcRtp4nI6yLSIiIvichDIvJv/cSdTIz/S0T+093fiyIyJuH9L4nIbhGpF5H/McDvc66I1IqIN2HdNSKyyZ1fKCJviUijiBwQkZ+ISKCfff1fEflOwvI33c/sF5G/6LXtZ0Rkg4g0i8heEbkv4e3X3WmjiLSKyPnx3zbh8x8TkTUi0uROP5bsbzMQEZnpfr5RRLaIyJKE9z4tIu+7+9wnIn/nrh/j/vs0isgREXlDRCy/jDD7wXPHeKAcmALcivNv/0t3eTLQAfxkgM+fC3wAjAF+APxCRGQI2z4J/BcwGrgP+NIA35lMjF8AvgKMBQJAPMHMAn7q7n+i+32V9EFV3wHagE/22u+T7nwU+Fv3eM4HLgH+eoC4cWNY7MZzGTAd6N1+3wb8N6AU+Axwm4hc7b73cXdaqqpFqvpWr32XA/8B/It7bA8A/yEio3sdwzG/zSAx+4F/B150P/c3wBMicrq7yS9wmu+KgTnAK+76bwA1QAUwDvgWYOOKjDBL6LkjBtyrql2q2qGq9ar6O1VtV9UW4LvAJwb4/G5VfVRVo8CvgAk4/3GT3lZEJgMLgHtUNaSqbwIr+/vCJGP8par+WVU7gOXAXHf954HnVPV1Ve0C/tH9DfrzG+BGABEpBj7trkNV16nq26oaUdVdwM/7iKMv17vxbVbVNpwCLPH4XlXV91Q1pqqb3O9LZr/gFADbVfXXbly/AbYBVyZs099vM5DzgCLge+6/0SvAc7i/DRAGZonIKFVtUNX1CesnAFNUNayqb6gNFDXiLKHnjjpV7YwviEhQRH7uNkk045zilyY2O/RSG59R1XZ3tug4t50IHElYB7C3v4CTjLE2Yb49IaaJift2E2p9f9+FUxu/VkTygGuB9aq6241jhtucUOvG8f/h1NYHc1QMwO5ex3euiKx2m5SagL9Kcr/xfe/utW43MClhub/fZtCYVTWx8Evc7+dwCrvdIvKaiJzvrv8nYAfwoojsFJFlyR2GSSVL6Lmjd23pG8DpwLmqOoqeU/z+mlFS4QBQLiLBhHVVA2x/IjEeSNy3+52j+9tYVd/HSVxXcHRzCzhNN9uA6W4c3xpKDDjNRomexDlDqVLVEuBnCfsdrHa7H6cpKtFkYF8ScQ2236pe7d/d+1XVNap6FU5zzO9xav6oaouqfkNVTwGWAF8XkUtOMBZznCyh565inDbpRrc99t7h/kK3xrsWuE9EAm7t7soBPnIiMa4APisiF7oXMO9n8L/3J4Gv4RQcv+0VRzPQKiJnALclGcNy4GYRmeUWKL3jL8Y5Y+kUkYU4BUlcHU4T0Sn97HsVMENEviAiPhG5AZiF0zxyIt7Bqc3/vYj4RWQRzr/RU+6/2U0iUqKqYZzfJAYgIp8VkdPcayVNONcdBmriMsPAEnruehAoAA4DbwN/HKHvvQnnwmI98B3gaZz+8n15kCHGqKpbgNtxkvQBoAHnot1A4m3Yr6jq4YT1f4eTbFuAR92Yk4nhefcYXsFpjnil1yZ/DdwvIi3APbi1Xfez7TjXDP7T7TlyXq991wOfxTmLqQf+Hvhsr7iPm6qGcBL4FTi/+8PAf1PVbe4mXwJ2uU1Pf4Xz7wnORd+XgFbgLeBhVV19IrGY4yd23cKkk4g8DWxT1WE/QzAm21kN3YwoEVkgIqeKiMft1ncVTlusMeYE2Z2iZqSNB57BuUBZA9ymqhvSG5Ix2cGaXIwxJktYk4sxxmSJtDW5jBkzRqdOnZqurzfGmIy0bt26w6pa0dd7aUvoU6dOZe3aten6emOMyUgi0vsO4W7W5GKMMVnCEroxxmQJS+jGGJMlrB+6MSYlwuEwNTU1dHZ2Dr6xGVR+fj6VlZX4/f6kP5NUQnfv6Psx4AUeU9Xv9Xr/R8DF7mIQGKuqpUlHYYzJeDU1NRQXFzN16lT6f/aJSYaqUl9fT01NDdOmTUv6c4MmdHfs6YdwnrpSA6wRkZXucKPxL//bhO3/Bph3PMEbYzJfZ2enJfMUERFGjx5NXV3dcX0umTb0hcAOVd3pjsT2FM74G/25EfdJL8aY3GLJPHWG8lsmk9AncfRTV2o4+qkoiQFMAaZx7DCh8fdvFZG1IrL2eEueuDW7jvD9P27DhiwwxpijpbqXy1JghfssyWOo6iOqWq2q1RUVfd7oNKh39zby01c/pLkjciJxGmOyTGNjIw8//PBxf+7Tn/40jY2NA25zzz338NJLLw0xspGTTELfx9GP0aqk/8dcLWWYm1tGFwUAqG/r75kIxphc1F9Cj0QGrvytWrWK0tLSAbe5//77ufTSS08kvBGRTEJfA0wXkWnuo7yW0seT2t1Hc5XhPK1k2JQX5gFwpC00nF9jjMkwy5Yt48MPP2Tu3LksWLCAiy66iCVLljBr1iwArr76as455xxmz57NI4880v25qVOncvjwYXbt2sXMmTP56le/yuzZs7n88svp6OgA4Oabb2bFihXd2997773Mnz+fM888k23bnIc51dXVcdlllzF79mxuueUWpkyZwuHDJ/QAqeM2aC8XVY2IyB3ACzjdFh9X1S0icj+wVlXjyX0p8JQOc+N2eTBeQ7eEbszJ6tv/voX39zendJ+zJo7i3itn9/v+9773PTZv3szGjRt59dVX+cxnPsPmzZu7u/09/vjjlJeX09HRwYIFC/jc5z7H6NFHPzd8+/bt/OY3v+HRRx/l+uuv53e/+x1f/OIXj/muMWPGsH79eh5++GF++MMf8thjj/Htb3+bT37yk9x999388Y9/5Be/+EVKjz8ZSfVDV9VVOA+lTVx3T6/l+1IXVv/K3SYXq6EbYwaycOHCo/pw/8u//AvPPvssAHv37mX79u3HJPRp06Yxd+5cAM455xx27drV576vvfba7m2eeeYZAN58883u/S9evJiysrJUHk5SMu5O0dGFltCNOdkNVJMeKYWFhd3zr776Ki+99BJvvfUWwWCQRYsW9XlHa15eXve81+vtbnLpbzuv1ztoG/1IyrixXPL9XoIBL/WtltCNMT2Ki4tpaWnp872mpibKysoIBoNs27aNt99+O+Xff8EFF7B8+XIAXnzxRRoaGlL+HYPJuBo6QHlhgIZ2S+jGmB6jR4/mggsuYM6cORQUFDBu3Lju9xYvXszPfvYzZs6cyemnn855552X8u+/9957ufHGG/n1r3/N+eefz/jx4ykuLk759wwkbc8Ura6u1qE+4OKqn7xJSTDAv/7FwhRHZYwZqq1btzJz5sx0h5E2XV1deL1efD4fb731FrfddhsbN248oX329ZuKyDpVre5r+4ytode1Wj90Y8zJY8+ePVx//fXEYjECgQCPPvroiMeQoQk9jw9q+24rM8aYdJg+fTobNmxIawwZd1EUnLtF69tCNp6LMcYkyMiEXhYM0BWJ0R7qc8gYY4zJSRmZ0K0vujHGHCsjE3p5od3+b4wxvWVmQu++/d96uhhjhqaoqAiA/fv38/nPf77PbRYtWsRg3asffPBB2tvbu5eTGY53uGRkQu9pcgmnORJjTKabOHFi90iKQ9E7oSczHO9wyciEXl5oNXRjzNGWLVvGQw891L1833338Z3vfIdLLrmke6jbP/zhD8d8bteuXcyZMweAjo4Oli5dysyZM7nmmmuOGsvltttuo7q6mtmzZ3PvvfcCzoBf+/fv5+KLL+biiy8GeobjBXjggQeYM2cOc+bM4cEHH+z+vv6G6T1RGdkPvSjPR8DrsTZ0Y05Wzy+D2vdSu8/xZ8IV3+v37RtuuIG77rqL22+/HYDly5fzwgsvcOeddzJq1CgOHz7Meeedx5IlS/p9XudPf/pTgsEgW7duZdOmTcyfP7/7ve9+97uUl5cTjUa55JJL2LRpE3feeScPPPAAq1evZsyYMUfta926dfzyl7/knXfeQVU599xz+cQnPkFZWVnSw/Qer4ysoYsI5YUBjtgAXcYY17x58zh06BD79+/n3XffpaysjPHjx/Otb32Ls846i0svvZR9+/Zx8ODBfvfx+uuvdyfWs846i7POOqv7veXLlzN//nzmzZvHli1beP/99weM58033+Saa66hsLCQoqIirr32Wt544w0g+WF6j1dG1tDBaXaxbovGnKQGqEkPp+uuu44VK1ZQW1vLDTfcwBNPPEFdXR3r1q3D7/czderUPofNHcxHH33ED3/4Q9asWUNZWRk333zzkPYTl+wwvccrI2vo4CR0a3IxxiS64YYbeOqpp1ixYgXXXXcdTU1NjB07Fr/fz+rVq9m9e/eAn//4xz/Ok08+CcDmzZvZtGkTAM3NzRQWFlJSUsLBgwd5/vnnuz/T37C9F110Eb///e9pb2+nra2NZ599losuuiiFR3usjK6h7znSPviGxpicMXv2bFpaWpg0aRITJkzgpptu4sorr+TMM8+kurqaM844Y8DP33bbbXzlK19h5syZzJw5k3POOQeAs88+m3nz5nHGGWdQVVXFBRdc0P2ZW2+9lcWLFzNx4kRWr17dvX7+/PncfPPNLFzojAp7yy23MG/evJQ1r/QlI4fPBbhv5RZWrKth87c/lcKojDFDlevD5w6H4x0+N2ObXEYXBmjtitAVsfFcjDEGMjihx+8WbbCbi4wxBsjghD66ezwXu7nImJOFDWmdOkP5LTM2oZcXOt1+rOuiMSeH/Px86uvrLamngKpSX19Pfn7+cX0uo3u5gCV0Y04WlZWV1NTUUFdXl+5QskJ+fj6VlZXH9ZmkErqILAZ+DHiBx1T1mLsGROR64D5AgXdV9QvHFclx6m5ysbtFjTkp+P1+pk2blu4wctqgCV1EvMBDwGVADbBGRFaq6vsJ20wH7gYuUNUGERk7XAHHlRT48YjV0I0xJi6ZNvSFwA5V3amqIeAp4Kpe23wVeEhVGwBU9VBqwzyWxyOUBe1uUWOMiUsmoU8C9iYs17jrEs0AZojIf4rI224TzTFE5FYRWSsia1PRzuaM52K9XIwxBlLXy8UHTAcWATcCj4pIae+NVPURVa1W1eqKiooT/tLywoD1QzfGGFcyCX0fUJWwXOmuS1QDrFTVsKp+BPwZJ8Gn3qFtsP7XoMroooD1QzfGGFcyCX0NMF1EpolIAFgKrOy1ze9xaueIyBicJpidqQszwfYXYeUd0NVsQ+gaY0yCQRO6qkaAO4AXgK3AclXdIiL3i8gSd7MXgHoReR9YDXxTVeuHJeLiCc605SDlhXk0doSJxuxGBmOMSaofuqquAlb1WndPwrwCX3dfw6t4nDNtOcDowimoQkN7iDFFeQN/zhhjslzm3fofr6G3HrS7RY0xJkEGJvTxzrTlgN0taowxCTIvoecVg78QWg5SZjV0Y4zplnkJHZxaekIN3W4uMsaYTE7orYk1dLu5yBhjMjehtxzA7/UwKt9nNXRjjCFTE3rReGipde8WzbMBuowxhkxN6MXjIdwOXS12t6gxxrgyNKHH7xattYRujDGuDE3o7t2irbWMLrQx0Y0xBjI2oR9dQ29oC9mDaY0xOS8zE3pRfDwXJ6FHYkpzRyS9MRljTJplZkLvvlu0tns8FxsX3RiT6zIzoYs47eitPQm9od3a0Y0xuS0zEzo47egttYwudIbNtQG6jDG5LnMTetE4p8mlyAboMsYYyOSEHq+hB/0A1nXRGJPzMjihj4dwG/mxdoIBr9XQjTE5L7MTOnQ/ucgSujEm12V+QnfHRbcmF2NMrsvchF4UT+jOuOg2hK4xJtdlbkJPqKGXFwY4Yt0WjTE5LnMTel4x+IPQepDRhQGO2I1Fxpgcl7kJXaT7yUXlhXl0hmO0h2w8F2NM7koqoYvIYhH5QER2iMiyPt6/WUTqRGSj+7ol9aH2oXgCtBzsfli03S1qjMllgyZ0EfECDwFXALOAG0VkVh+bPq2qc93XYymOs29F47rb0MHuFjXG5LZkaugLgR2qulNVQ8BTwFXDG1aS3LtF7fZ/Y4xJLqFPAvYmLNe463r7nIhsEpEVIlLV145E5FYRWSsia+vq6oYQbi/F4yDcxhi/k8itL7oxJpel6qLovwNTVfUs4E/Ar/raSFUfUdVqVa2uqKg48W91n1xUHqsHsL7oxpiclkxC3wck1rgr3XXdVLVeVePZ9DHgnNSENwj3yUWFocP4vWI1dGNMTksmoa8BpovINBEJAEuBlYkbiMiEhMUlwNbUhTgAt4YuLQft5iJjTM7zDbaBqkZE5A7gBcALPK6qW0TkfmCtqq4E7hSRJUAEOALcPIwx9+geoKuWMUXjqWu1JhdjTO4aNKEDqOoqYFWvdfckzN8N3J3a0JIQv1u0pZbKsgI+rGsb8RCMMeZkkbl3ikLC3aK1VJUFqWloR1XTHZUxxqRFZid0cEZdbKmlqjxIZzhmzS7GmJyV+QndHc+lqrwAgJqGjjQHZIwx6ZEdCb31IJVlQQD2HmlPc0DGGJMe2ZHQQ61UBp2RFq2GbozJVZmf0N0nFwW76hlTFLAaujEmZ2V+Qk94clFlWdBq6MaYnJUFCd29SbX1IJVlBextsBq6MSY3ZUFCd8ZzcXq6BNnf2EE0Zn3RjTG5J/MTet6o7rtFq8qChKNKbXNnuqMyxpgRl/kJXcR9clFtT190uzBqjMlBmZ/QwWlHT+yLbhdGjTE5KEsSuvNs0Yml+YjYzUXGmNyUJQndebZons/L+FH51tPFGJOTsiShO3eL0tXijrpoTS7GmNyTHQm9KH5zkdMX3S6KGmNyUXYk9IQnF1WWBznQ3EkoEktvTMYYM8KyK6G31FJVVoAq7G+0ZhdjTG7JvoReHu+6aM0uxpjckh0JPW8U+ArcAbrsQRfGmNyUHQk94dmiE0oK8HnE+qIbY3JOdiR0gPJToH47Xo8wsbTA7hY1xuSc7EnoY2dC3QcQi1JVXmA1dGNMzsmihD4LIp3QsIvKUru5yBiTe5JK6CKyWEQ+EJEdIrJsgO0+JyIqItWpCzFJY2c600PvU1VewOHWLjpC0REPwxhj0mXQhC4iXuAh4ApgFnCjiMzqY7ti4GvAO6kOMikVpwMCh7Z2d12ssa6LxpgckkwNfSGwQ1V3qmoIeAq4qo/t/hfwfSA9T5cIFELZVDj0fsIwupbQjTG5I5mEPgnYm7Bc467rJiLzgSpV/Y+BdiQit4rIWhFZW1dXd9zBDmrsLKeGbn3RjTE56IQvioqIB3gA+MZg26rqI6pararVFRUVJ/rVxxo7E+p3UFEAeT6P9XQxxuSUZBL6PqAqYbnSXRdXDMwBXhWRXcB5wMq0XRiNRZAjH1JZVsDeI1ZDN8bkjmQS+hpguohME5EAsBRYGX9TVZtUdYyqTlXVqcDbwBJVXTssEQ9k3Gxn6l4YtTZ0Y0wuGTShq2oEuAN4AdgKLFfVLSJyv4gsGe4Aj0v5qeDxw8Etzrjo1oZujMkhvmQ2UtVVwKpe6+7pZ9tFJx7WEPkCMGa6U0OfFKSpI0xzZ5hR+f60hWSMMSMle+4UjRs70725yO26aBdGjTE5IjsTeuNuphQpgF0YNcbkjCxM6M5NrFXRPYDdLWqMyR1ZmNCdMV2Km/9MUZ7PLowaY3JG9iX00qngK0AObXP7olsN3RiTG7IvoXs8MPaM7guj1hfdGJMrsi+hQ/eYLvG+6Kqa7oiMMWbYZWlCnwmttZxWGKI9FOVIWyjdERljzLDL3oQOzPA6Q87Y80WNMbkgSxO603VxSmQXAB8eak1jMMYYMzKyM6EXT4D8Esa0f0hRno8NexvSHZExxgy77EzoIjB2Np66rcytKmX97sZ0R2SMMcMuOxM6dI/pMr+qhG21zbR1RdIdkTHGDKvsTuidTZw7NkRM4d2axnRHZIwxwyqLE7pzYXRu4AAAG/Y0pjEYY4wZflmc0J2ui4VNf+bUikLW77YLo8aY7Ja9CT1YDkXj4dBW5k8uY8PeRrtj1BiT1bI3oUPPhdEpZRxpC7Gr3sZ1McZkryxP6LPg0DbmV5UAWLOLMSarZXlCnwmRDqb76ynO87F+jyV0Y0z2yu6EPs7p6eI5+C5zJ5ey3nq6GGOyWHYn9PFnQ34JbH+JeZPL+KC2mVa7wcgYk6WyO6F7fXDaZbD9BeZXjXJuMNrbmO6ojDFmWGR3QgeY8Sloq6PavxuwC6PGmOyVVEIXkcUi8oGI7BCRZX28/1ci8p6IbBSRN0VkVupDHaLTLgXxULTnZU4bW2QXRo0xWWvQhC4iXuAh4ApgFnBjHwn7SVU9U1XnAj8AHkh1oEMWLIeqc+HPf2T+5FK7wcgYk7WSqaEvBHao6k5VDQFPAVclbqCqzQmLhcDJlTFnfAoOvMsFY0M0tofZebgt3REZY0zKJZPQJwF7E5Zr3HVHEZHbReRDnBr6nX3tSERuFZG1IrK2rq5uKPEOzYzFAJwXXQdYO7oxJjul7KKoqj6kqqcC/wD8z362eURVq1W1uqKiIlVfPbiKM6BkMmMPvEpxvs/6oxtjslIyCX0fUJWwXOmu689TwNUnEFPqicCMTyEfvcaCyiAb7MKoMSYLJZPQ1wDTRWSaiASApcDKxA1EZHrC4meA7akLMUVmLIZwO1eWfMgHB1to6QynOyJjjEmpQRO6qkaAO4AXgK3AclXdIiL3i8gSd7M7RGSLiGwEvg58ebgCHrKpF4I/yMLQGlTh3b1N6Y7IGGNSypfMRqq6CljVa909CfNfS3FcqefPh1MuZsKB1xC5gvV7Grhw+ph0R2WMMSmT/XeKJppxOZ7mvVw2+ojdYGSMyTq5ldCnXw7ANUVbWLe7gVAkluaAjDEmdXIroY+aCBPO5vzIGlo6I7z25xHsC2+MMcMstxI6wIzFlNRv4JRgF89uqEl3NMYYkzI5mNA/hWiM2yfv4qWth2jqsO6LxpjskHsJfcI8KBzLJZ4NhCIxVr13IN0RGWNMSuReQvd4YPrllOx7ldljPDyz3ppdjDHZIfcSOsA5NyNdzSwbt4Y1uxrYe6Q93REZY8wJy82EXrUAplzI+Qd/g58Iz24YaGgaY4zJDLmZ0AEuvAtf637+dvy7PLthnz30whiT8XI3oZ92KYybw02RZ9l1uIWN9vBoY0yGy92ELgIX3EVJ604W+zdas4sxJuPlbkIHmH0NlE7mm4XPs3LjPhsKwBiT0XI7oXt98LE7OaVzC9M7N/PqB4fSHZExxgxZbid0gLk3ocHR3Jn/nDW7GGMymiX0QBA59zYu0vXs3bqWpnYbCsAYk5ksoQMs+EuiviB/4VnJc+/tT3c0xhgzJJbQAYLleKpv5irv/+MPr75tF0eNMRnJErpLzr8D8Xi5ruXfeHrNnnSHY4wxx80SelzJJORjf8N1vtfZ8KcnaeuKpDsiY4w5LpbQE8iiu2kvn8nd0Z/y5Cvr0x2OMcYcF0voiXwBgjc8Tql0MO3tb1Hf0pnuiIwxJmmW0HsbN4umjy3jUlnDGyt+nO5ojDEmaUkldBFZLCIfiMgOEVnWx/tfF5H3RWSTiLwsIlNSH+rIGXPp19lZOJdLd/2I/bs+SHc4xhiTlEETuoh4gYeAK4BZwI0iMqvXZhuAalU9C1gB/CDVgY4oj4eipY8B0P70VyEWTXNAxhgzuGRq6AuBHaq6U1VDwFPAVYkbqOpqVY0/9udtoDK1YY68sVXTee20b3Jax7vUvvDP6Q7HGGMGlUxCnwTsTViucdf15y+B508kqJPFhZ/7G15mIaPf+QFsW5XucIwxZkApvSgqIl8EqoF/6uf9W0VkrYisraurS+VXD4uSYIB9F36PrbFKeOpGeOW7ELO7SI0xJ6dkEvo+oCphudJddxQRuRT4H8ASVe3qa0eq+oiqVqtqdUVFxVDiHXFLF83j+xMf5HexT8DrP4Df3AAdDekOyxhjjpFMQl8DTBeRaSISAJYCKxM3EJF5wM9xknlWDSoe8Hn4P1/6GD8uvIv/7fkq+uFqeORiOLgl3aEZY8xRBk3oqhoB7gBeALYCy1V1i4jcLyJL3M3+CSgCfisiG0VkZT+7y0jlhQEe/8oCnoxexteD3yUWbofHLoUNT1gTjDHmpCHpetp9dXW1rl27Ni3fPVSv/bmOr/zyv7j6NB//zI+QvW/BuDPhkn+E6Zc7zyk1xphhJCLrVLW6r/fsTtHj8IkZFdx75Wye2R7h++N/CNc+CqEWePJ6ePxT8NEb6Q7RGJPDLKEfpy9/bCpfOm8KP3tjN091ngd3rIXPPgiNe+FXn4V/vQq2/wmi9uQjY8zI8qU7gEx075Wz2FXfxrJn3uOj+ja+efmX8Z29FNY+Dm/8MzzxeQiOhtnXwJnXQeVC8FjZaYwZXtaGPkSd4Sj3P/c+T76zh3OnlfN/vjCPscX5EOmCHS/Beyvgg+ch0gElk2H21TDlAqishsIx6Q7fGJOhBmpDt4R+gp5ZX8O3nn2P4nw/P7lxHueeMrrnza4W5w7T934LO1dDzH1oRtk0qFzgvKacD+Pm2AVVY0xSLKEPs221zdz2b+vZc6Sdf1h8Ol+96BSkd4IOtcOBjVCzxnntXQOttc57RePg1E/CqZfAqRdbDd4Y0y9L6COgpTPM36/YxPObazm7soTbLz6NS2eOw+Ppp+atCk01sOsN2PEyfPgKdBwBBCbOddrdJ5wNE86CijPA6x/JwzHGnKQsoY8QVeW362r4ySs72HOkndPHFfPXF5/KZ86cgM87yEXRWNSpwe94GXa+Cvs3QrjNec+bB+NmOU0zZVOhdAqUTnZeRePsgqsxOcQS+giLRGM8t+kAD7+6gz8fbGXK6CD//eOncvW8iQQDSXYsikXhyE448G7P69BWaOs1soI3D0qrnORe4k5LpzjrCsohfxTkl4Av39rpjckCltDTJBZT/rT1IA+t3sGmmiaK8nwsmTuRpQuqOHNSybHt7MkItUPTXmjcA427oWG3O+++2g/3/TlvAPJGOd0p47X7sik9BcCoiVBYAR7viR20MWZYWUJPM1Vl7e4Gnl6zl+c27aczHGPmhFEsXVDFkrMnUlYYSN2Xhdqcm5yaaqCz0X01QWezM22r60n+nY1Hf1Y8EBzjNOMUjXWmwXKnEIhPC8qd+YJyKCgDXwpjN8YMyhL6SaS5M8zKjft5es1e3tvXhEdgblUpi04fy6LTK5gzsaT/C6mp1tnkJPaG3dByAFoPQetBd1rrTNuPOH3p+xMocpN8GfgKnIu3Xr9zRuDxgb/ALSDGQfEEKHanBeXOe/4Cawoy5jhYQj9JbdnfxAtbDvLaB4fYtK8JVRhdGODjMyo4/5TRVE8tY9qYwqE1zaRSqN3pgdN+BNrre+Y7Gp35jgY38Xc6Qx5EQxALO/Phdmg5OHCh4A/2vApKnJp/4iu/FPKKIFDsTot6pv4gBAqdgsGuE5gcYAk9A9S3dvH69jpe+6CO17cf5khbCHASfPXUMhZMLeecKWXMnDCKfH+GtXOrQlcztNT2vDobnWQfanem4Q6nuaizySkgEl+xJMfFEU9Pgg8UOdO8Yne5EPyFEAi6ZwbufKDQKSgChT2FRKAI/PnOGYcvz9neuo2ak4Ql9AwTiyk7D7eyZlcDa3YdYe2uBvYccZ7B7fUI08cWMXtiCXMmjWLOpBJmjCumpCBLE46qk/C7WiHU6tx9G2rtWe4uFNp6CodQq1M4dLnTUHxbt9AId0C0z4dq9U+8bjOS1yk44i+P10n8eUU9BUegyClI8kucs4uCUnda5mzny3cKiniB4cvvaX6yi9JmEJbQs8DB5k427Glg875mNu9vYvO+Jg63hrrfH1MUYNqYQvdVxCkVzvzk8mDm1ehHQjTiJv+EhB8vJOJJP9LpvMKdTpNRNOQUMLEoaAw06sxHOhM+3+YWJi3OWUhX8/HF5c1zzyKCPYnf63fWewPOvC/PXZ939LzX51y36H55nX0cVbC48/6Cnu28fvD47X6GDGEJPQupKodauti8r4kdh1r56HAbO+va2Hm4jcOtPbVPEZhYUsC0MYVMHRNk6uhCJpUWUFkWZFJZAWVBf/rb6LNZNOIk9Y4GJ8GH2pwB3MIdzrS70HCbnbqbn9yzjWio57pENOR8pnva5e7DXReLONtqdGixisc5a/AXuNc0Cnpe8bOI+JmFP98tcPJ7Ch5/whlH7zMQb6CPAsfXUyD58p1CyQqVQQ2U0G343AwlIowblc+4UflcMnPcUe81d4b5qK6NXfVtfHTYee063MYfNu6npTNy1LYFfi+TygqYUJLP2OJ8xo7KY1xxHuNGOfMVRflUFOdRELBa/pB4fW6Xz/KR+874WUQs4pxZdDY5F7A7m5xCpaPRKQRi4Z5CIBZ1C4o+Cpdwh3MG0n7YPVvpcvYbL5iSvcaRDG/AedFHJcOf79xLEb9ZLj4fL1S8AfdsJdBzNuPxHl2AiNcpNLrnvQkFS0GvayfBnuUMKWgsoWehUfl+zq4q5eyq0qPWqypNHWFqGjqoaehgX2MH+xo62NfYTm1zFx8eOsyhli4isWPP2oryfFQU51FRlEdFcR5jigLu1HlVFOcxpjiP0YUBa+JJNxGnIPH6nIRUUAZlw/h9sWjP2Ub8+kT32Ud86p5BxCJuQRJ1zzz62fYY6uy7q7nnvormA85y/DPx3lXDIV5o+IPOvRfePHfaez7Q02033pTVPfX1LM/4FEycl/owU75Hc9ISEUqDAUqDAeZMKulzm1hMaWgPcbC5i0MtndS1dFHX2uVM3dfWA83UtXYdU9uPK8rzMaYowOgiJ8GXBv2UFLivYICSAj+lBX7Kgs57ZYUBCgNea/rJVB6v22MomO5InIe2R0NOQRFzr3EknolozL0G4p7BxBKug8QLpN7TcIdzRhI/a4m4+48XItGQ00QWazq6eax73u3CG+/Kizo37llCN8PN4xEnERflMYtRA27bGY5yuLWLw60h6lq6qG/tor7NnW8LUd/axe76djbVhGnsCNEZjvW7L79XKCkIMKrAR3G+n1H5Pkbl+ynO9zHKLQxKg24hUOCnJOhnVL7zKszzDj74mckNHg948p0zk5NVbIjXOJJgCd0MWb7fS2VZkMqy5GpmXZEoTR1hmtrDNHaEaWgL0djuJPuG9jCN7SGaOyI0d4Zp6Yywv7GD5s4IzR1huiL9FwYAwYCX4nynMCjKcwqB4nwfo9x1xXk+ivJ9FOW5L3e+ON9HobuuMOAbubt0Te4axq6pltDNiMnzeRlb7HUe1XecOsNOYdDYHqah3SkI4om/tTNCizvf0uVMnWsF7c66zvCAZweJCgPensQfLwjynKTvFBg+t6DwOwWFWyAEA14KAz4KAl4K87zk+7xWOJgRZwndZIR8v5d8v5dxo4Z2Kh2OxmjrijgFQJfzaukM09oVpbUz4rzX5UxbOyO0htxpV4S6li5au5wzh9auCMn09BWBoN9LoVsYFOY5Cb8oz036AR/BPC/BgJdgwCkQ8v1eCtzjLAjE3+vZttDdzq41mP4kldBFZDHwY8ALPKaq3+v1/seBB4GzgKWquiLFcRpzQvxeT/cF4RMRiyltoYhb83cKhbZQlI5QhLauKO3hKO1dEdpCUdriBYQ7beuKUtvcSUcoSlsoQnuXM+2jU1G/RJyupvFCoOflSygEet4rSDxzOOozPgoCnqMKkXy/F6+dVWS0QRO6iHiBh4DLgBpgjYisVNX3EzbbA9wM/N1wBGnMycLjEbepJTVDLagqXZEYneEoHeEoHaEoneFY93xbKEK7W1jEC4j2UE/B0R6K0u5ud7i1q3u5IxShPRxN6mwiUZ7P4xQM7llCQaAn4ef5vOT7ewqB+HvBQOK8j3y/hwK/l7zuwsLTaz8eO8sYJsnU0BcCO1R1J4CIPAVcBXQndFXd5b6XXEOlMQZwupLGa8elKd63qtIZjtEeOjrxt3dFewqQsDPfGXYLArcgcQqFKO2hCB3hKC2dEerCXd2FT2f3Z4//v3z8LCMxwQd8nu75PL9ToAQDXrdZytddgAS8HvL8HvJ87rbu9t3zPi95/p595fu95Ps8OdMLKpmEPgnYm7BcA5w7lC8TkVuBWwEmT548lF0YY5IkIt217NHD9B2xmNIR7ikAOo5K9k7CTywA4gVGh3uW0RWO0RWJ0hWJOa9wlKb2EAdCPQVMeygypIIjkc/TU3DGzyAKAj1NTQGvh4BP8Hs9BLwe/G4BUZBwNhI/Mwm47wXcV7xwyff3FCjxs5mAd2TPRkb0oqiqPgI8As5YLiP53caY1PN4pPvC73CKxpRQJCH5h2OEok6BES8IuhLeTyxMjlqOROkMHX120tQRJhyJEYrGCEdjhCLONN70FT2eixx96OtM4q5LZ3Dl2RNT9Ov0SOZfYR9QlbBc6a4zxpgR4fX0nG2MNCe595xddEVibuESO6qQCcULjsQCJhylKxpzz0R6ti0NDs9w18kk9DXAdBGZhpPIlwJfGJZojDHmJOP3evB7PSm7ED6cBr1SoKoR4A7gBWArsFxVt4jI/SKyBEBEFohIDXAd8HMR2TKcQRtjjDlWUg1fqroKWNVr3T0J82twmmKMMcakSW705THGmBxgCd0YY7KEJXRjjMkSltCNMSZLWEI3xpgsYQndGGOyhOjxDseWqi8WqQN2D/HjY4DDKQznZJTtx2jHl/my/RhP1uOboqoVfb2RtoR+IkRkrapWpzuO4ZTtx2jHl/my/Rgz8fisycUYY7KEJXRjjMkSmZrQH0l3ACMg24/Rji/zZfsxZtzxZWQbujHGmGNlag3dGGNML5bQjTEmS2RcQheRxSLygYjsEJFl6Y7nRInI4yJySEQ2J6wrF5E/ich2d1qWzhhPhIhUichqEXlfRLaIyNfc9dl0jPki8l8i8q57jN92108TkXfcv9WnRSSQ7lhPhIh4RWSDiDznLmfb8e0SkfdEZKOIrHXXZdTfaUYldBHxAg8BVwCzgBtFZFZ6ozph/xdY3GvdMuBlVZ0OvOwuZ6oI8A1VnQWcB9zu/ptl0zF2AZ9U1bOBucBiETkP+D7wI1U9DWgA/jJ9IabE13AechOXbccHcLGqzk3of55Rf6cZldCBhcAOVd2pqiHgKeCqNMd0QlT1deBIr9VXAb9y538FXD2SMaWSqh5Q1fXufAtOQphEdh2jqmqru+h3Xwp8Eljhrs/oYxSRSuAzwGPuspBFxzeAjPo7zbSEPgnYm7Bc467LNuNU9YA7XwuMS2cwqSIiU4F5wDtk2TG6zREbgUPAn4APgUb3EY6Q+X+rDwJ/D8Tc5dFk1/GBUwi/KCLrRORWd11G/Z0m9Qg6kz6qqiKS8X1LRaQI+B1wl6o2OxU8RzYco6pGgbkiUgo8C5yR3ohSR0Q+CxxS1XUisijN4QynC1V1n4iMBf4kItsS38yEv9NMq6HvA6oSlivdddnmoIhMAHCnh9IczwkRET9OMn9CVZ9xV2fVMcapaiOwGjgfKBWReKUpk/9WLwCWiMgunGbOTwI/JnuODwBV3edOD+EUygvJsL/TTEvoa4Dp7tX1ALAUWJnmmIbDSuDL7vyXgT+kMZYT4ra1/gLYqqoPJLyVTcdY4dbMEZEC4DKcawWrgc+7m2XsMarq3apaqapTcf7PvaKqN5ElxwcgIoUiUhyfBy4HNpNhf6cZd6eoiHwapz3PCzyuqt9Nb0QnRkR+AyzCGarzIHAv8HtgOTAZZ4jh61W194XTjCAiFwJvAO/R0/76LZx29Gw5xrNwLph5cSpJy1X1fhE5BadGWw5sAL6oql3pi/TEuU0uf6eqn82m43OP5Vl30Qc8qarfFZHRZNDfacYldGOMMX3LtCYXY4wx/bCEbowxWcISujHGZAlL6MYYkyUsoRtjTJawhG7MEIjIoviog8acLCyhG2NMlrCEbrKaiHzRHat8o4j83B1Eq1VEfuSOXf6yiFS4284VkbdFZJOIPBsf+1pEThORl9zxzteLyKnu7otEZIWIbBORJyRxgBpj0sASuslaIjITuAG4QFXnAlHgJqAQWKuqs4HXcO7OBfhX4B9U9SycO1vj658AHnLHO/8YEB99bx5wF87Y/KfgjHliTNrYaIsmm10CnAOscSvPBTiDK8WAp91t/g14RkRKgFJVfc1d/yvgt+74HpNU9VkAVe0EcPf3X6pa4y5vBKYCbw77URnTD0voJpsJ8CtVvfuolSL/2Gu7oY5/kThuSRT7/2TSzJpcTDZ7Gfi8O751/PmQU3D+7uOjBH4BeFNVm4AGEbnIXf8l4DX3KUs1InK1u488EQmO5EEYkyyrUZisparvi8j/xHkKjQcIA7cDbcBC971DOO3s4AyP+jM3Ye8EvuKu/xLwcxG5393HdSN4GMYkzUZbNDlHRFpVtSjdcRiTatbkYowxWcJq6MYYkyWshm6MMVnCEroxxmQJS+jGGJMlLKEbY0yWsIRujDFZ4v8HpPRiWlsMXKAAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_summary(model, history)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating network...\n"
     ]
    }
   ],
   "source": [
    "# evaluate the network\n",
    "print(\"Evaluating network...\")\n",
    "predictions = model.predict(X_test_nn)\n",
    "preds = predictions > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yash\\anaconda3\\envs\\open_cv\\lib\\site-packages\\ipykernel_launcher.py:6: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  \n",
      "C:\\Users\\Yash\\anaconda3\\envs\\open_cv\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Correct Predictions: 3429\n",
      "> Wrong Predictions: 156\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWcAAAD4CAYAAAAw/yevAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAYD0lEQVR4nO3de7zVVZ3/8df7HBDwQqICImAioY4XZAStvKWRAjaPvJQG0yO1mE410vz0Z17QvF8rHWdMo45KSilGkYmmIjKm4yQKCuIN8ICYMCegMEBFFPjMH+eLbuBc9jnsc/b3LN9PH+vB3ut7Wev7ePB4s1zf9f1uRQRmZpYvFeXugJmZbc3hbGaWQw5nM7MccjibmeWQw9nMLIc6tHYDu54x0ctBbCtv3j6y3F2wHNq+o7St5+jyj2OKzpy1s2/Z5vZaS6uHs5lZm1IaEwIOZzNLy7YPvnPB4WxmafHI2cwshzxyNjPLoYrKcvegJBzOZpYWT2uYmeWQpzXMzHLII2czsxzyyNnMLIc8cjYzy6FEVmuk8U+Mmdkmqii+NHUqabyk5ZJeKqj7taQ5WVksaU5Wv5ektQXbflZwzGBJL0qqkXSz1PTci0fOZpaWipLOOd8J3AJM2FQREV/d9FnSjcCqgv0XRsSges4zDvgW8AzwEDAceLixhj1yNrO0lHDkHBFPAivrbaZu9HsaMLHR7ki9gK4RMSPqfrR1AnBSU207nM0sLVLxZdscBSyLiNcK6vpJmi3pCUlHZXW9gSUF+yzJ6hrlaQ0zS0szbghKqgKqCqqqI6K6yMNHsfmouRbYMyL+Jmkw8HtJBxTdmS04nM0sLc1YSpcFcbFh/FETUgfgFGBwwbnWAeuyz89JWgjsAywF+hQc3iera5SnNcwsLW0zrfEFYF5EfDhdIam7pMrs897AAGBRRNQCqyV9JpunPh24v6kGHM5mlpbSLqWbCDwN7CtpiaTR2aaRbH0j8Ghgbra07rfAdyJi083EfwVuB2qAhTSxUgM8rWFmqSnh49sRMaqB+jPrqZsMTG5g/1nAgc1p2+FsZmnx49tmZjmUyOPbDmczS4tHzmZmOeRXhpqZ5ZBHzmZmOeSRs5lZDnnkbGaWP6pwOJuZ5U4R77FvFxzOZpaWNLLZ4WxmafHI2cwshxzOZmY5VOEbgmZmOZTGwNnhbGZp8bSGmVkOOZzNzHLI4WxmlkMOZzOzHFKFw9nMLHc8cjYzyyGHs5lZHqWRzaTxKI2ZWUZS0aWIc42XtFzSSwV1l0taKmlOVk4o2DZWUo2k+ZKGFdQPz+pqJF1YzHU4nM0sKaUMZ+BOYHg99TdFxKCsPJS1uz8wEjggO+ankiolVQK3AiOA/YFR2b6N8rSGmSWllO/WiIgnJe1V5O4nAvdGxDrgdUk1wGHZtpqIWAQg6d5s31caO5lHzmaWFhVfJFVJmlVQqopsZYykudm0R7esrjfwZsE+S7K6huob5XA2s6Q0Z1ojIqojYkhBqS6iiXFAf2AQUAvc2BrX4WkNM0tKay+li4hlBW3dBjyYfV0K9C3YtU9WRyP1DfLI2cySUuIbgvWdv1fB15OBTSs5pgAjJXWS1A8YADwLzAQGSOonaTvqbhpOaaodj5zNLCmlfHxb0kTgGGA3SUuAy4BjJA0CAlgMfBsgIl6WNIm6G33rgbMiYkN2njHAVKASGB8RLzfVtsN5G908+tMcP2gP/rr6PY68+GEAzj/pQE4/pj9/Xb0OgKt/+wKPza2l72478PR1J1BTuwaAWQv/yvfvmkWX7SoZf9YR9OuxExsimDp7KVf+5oWyXZO1nl9NuJP7Jv8WSXxqwACuuPo65sx+nv+48cds3LiR7bffniuuuY499/xkubvabpVyWiMiRtVTfUcj+18DXFNP/UPAQ81p2+G8jSY+tYjbH1vAT6s+s1n9uKnzufXheVvtv3j52xxz6SNb1d/68DyemrecjpUV3HfBsQwd2Ivpc2tbrd/W9pYvW8bEu3/J5Pv/QOfOnTn/3LOZ+vAfuOO2n3PTzT9l7/79mXTvPdz+83Fcec315e5uu+XHtw2Ap+evoO9uO2zTOda+v4Gn5i0H4IMNG5n7xlvs0W37UnTPcmbD+g2sW/ceHTp04L21a+nevQeSeOedtwFYs2YN3bv3KHMv27ePTThL2o+6BdOb1uUtBaZExKut2bH27l+GDuCrR/RjzusruWTi86x69wMA9uy+I49fOZw1az/g2slzmbFgxWbHdd2+I8MG9ebnj84vR7etFfXo2ZPTz/wmI77weTp17sRnDz+Czx5xJJdecTXf+24VnTp3ZocddmTCPb8ud1fbtzSyufHVGpIuAO6l7nKfzYqAiY09H164sPu9BdNL2d924Rf/VcPg8x7kc5c8zLK/r+WqUYcAsOzvazn4nPs59tJHuGTi81R/57Ps1Pmjfx8rK8Rt3z2c6mkLeGPFO+XqvrWS1atW8cfHp/Pg1Md49L+eZO3atfzhgSncPeEufjKumqnTn+DEk07hxh95SmNbtPZqjbbS1FK60cChEXF9RPwqK9dT90ji6IYOKlzY3XmfoaXsb7uwYvV7bIwgAiY8sZBD9t4FgPfXb+Std94H4IXFb/H68rfpv3vXD4+76RuHsegvazxqTtQzM55mj9592GWXXejYsSOfH3occ2Y/z4L58zho4MEAHD9iBC/MmV3mnrZvFRUquuRZU+G8Edijnvpe2TarR89PdP7w8xcH9+HVJasA2HWnTlRk/1p/svsO9N99JxavqJtrvOjLB9G1S0cuuuf5tu+wtYnde/XixbkvsHbtWiKCZ595mr379+ftt9fwxuLXAZjxpz/Rb++9y9zT9i2VkXNTc85nA9MlvcZHz4bvCXwKGNOK/Wo3qr97OEfs14Ndd+zEizedyPX3vciR+/XgwD27EcCf//o25/5iJgCH79udC08ZyAfrN7IxgnPvnMnf33mfPbp14dwvHciC/13F41fUvQDr9ukL+NUTi8p4ZVZqBw08mC8cdzz/fNopVFZ2YL/9/oEvn/pVevbcne+f829IFXTt2pXLr7q23F1t13KeuUVTRDS+g1RB3TRG4Q3BmZsWVzdl1zMmNt6AfSy9efvIcnfBcmj7jtserfteMLXozJn/w2G5jfImV2tExEZgRhv0xcxsm6UycvY6ZzNLSt5v9BXL4WxmSXE4m5nlkKc1zMxyKO9L5IrlcDazpDiczcxyKJFsdjibWVp8Q9DMLIc8rWFmlkOJZLPD2czS4pGzmVkOJZLNDmczS0sqI+em3udsZtaulPJl+5LGS1ou6aWCuh9LmidprqT7JO2c1e8laa2kOVn5WcExgyW9KKlG0s0q4l8Qh7OZJUUqvhThTmD4FnXTgAMjYiCwABhbsG1hRAzKyncK6scB3wIGZGXLc27F4WxmSSnlL6FExJPAyi3qHo2I9dnXGUCfJvrTC+gaETOi7gX6E4CTmmrb4WxmSWnOyLnwx6izUtXM5r4JPFzwvZ+k2ZKekHRUVtcbWFKwzxI++vGSBvmGoJklpTk3BCOiGqhuYTsXA+uBu7OqWmDPiPibpMHA7yUd0JJzg8PZzBLTFqs1JJ0J/BMwNJuqICLWAeuyz89JWgjsQ91P+xVOffTJ6hrlaQ0zS0opV2vUR9Jw4HzgSxHxbkF9d0mV2ee9qbvxtygiaoHVkj6TrdI4Hbi/qXY8cjazpJRy4CxpInAMsJukJcBl1K3O6ARMy0bpM7KVGUcDV0r6ANgIfCciNt1M/FfqVn50oW6OunCeul4OZzNLSimnNSJiVD3VdzSw72RgcgPbZgEHNqdth7OZJSWRBwQdzmaWlopE0tnhbGZJ8cv2zcxyKJFsdjibWVpSeSudw9nMkpJINjuczSwtIo10djibWVI852xmlkNerWFmlkNe52xmlkOJZLPD2czS4qV0ZmY5lEg2O5zNLC2ViaSzw9nMkuJpDTOzHEpkJZ3D2czS4pGzmVkOJZLNDmczS4tHzmZmOVSZyKSzw9nMkpJGNENFuTtgZlZKFVLRpSmSxktaLumlgrpdJE2T9Fr2Z7esXpJullQjaa6kQwqOOSPb/zVJZxR1HS24djOz3JKKL0W4Exi+Rd2FwPSIGABMz74DjAAGZKUKGFfXH+0CXAZ8GjgMuGxToDfG4WxmSZFUdGlKRDwJrNyi+kTgruzzXcBJBfUTos4MYGdJvYBhwLSIWBkRbwHT2Drwt+JwNrOkNGfkLKlK0qyCUlVEEz0jojb7/BegZ/a5N/BmwX5LsrqG6hvlG4JmlpTmrNaIiGqguqVtRURIipYe3xiPnM0sKaWc1mjAsmy6guzP5Vn9UqBvwX59srqG6hvV6iPnpXeMau0mrB3qduiYcnfBcmjt7Fu2+RxtMOKcApwBXJ/9eX9B/RhJ91J3829VRNRKmgpcW3AT8HhgbFONeFrDzJJSyicEJU0EjgF2k7SEulUX1wOTJI0G3gBOy3Z/CDgBqAHeBb4BEBErJV0FzMz2uzIitrzJuBWHs5klpZQPCEZEQ//rP7SefQM4q4HzjAfGN6dth7OZJcWPb5uZ5VAi2exwNrO0JPJSOoezmaWlmHdmtAcOZzNLSioPbziczSwpiQycHc5mlhav1jAzy6FEstnhbGZp8Q1BM7McSiSbHc5mlhZPa5iZ5ZAS+YlXh7OZJaVDIgudHc5mlpRSvjK0nBzOZpYUzzmbmeVQIgNnh7OZpcXrnM3McqjSNwTNzPKnwkvpzMzyJ5FZDYezmaUlldUaiczOmJnVqZCKLo2RtK+kOQVltaSzJV0uaWlB/QkFx4yVVCNpvqRh23IdHjmbWVJKNa0REfOBQXXnVCWwFLgP+AZwU0TcsHm72h8YCRwA7AE8JmmfiNjQkvY9cjazpFRWqOjSDEOBhRHxRiP7nAjcGxHrIuJ1oAY4rKXX4XA2s6RUNKNIqpI0q6BUNXDakcDEgu9jJM2VNF5St6yuN/BmwT5LsroWX4eZWTIkFV0iojoihhSU6nrOtx3wJeA3WdU4oD91Ux61wI2tcR0OZzNLippRijQCeD4ilgFExLKI2BARG4Hb+GjqYinQt+C4PlldiziczSwppVqtUWAUBVMaknoVbDsZeCn7PAUYKamTpH7AAODZll6HV2uYWVJKucxZ0g7AccC3C6p/JGkQEMDiTdsi4mVJk4BXgPXAWS1dqQEOZzNLTEUJn0KJiHeAXbeo+3oj+18DXFOKth3OZpaUVOZqHc5mlhT/EoqZWQ6lEc0OZzNLjEfOZmY5VOlwNjPLnzSi2eFsZolJZODscDaztPhnqszMcsgjZzOzHJJHzmZm+ePVGmZmOZRINjuczSwtDmczsxzynLOZWQ6V8I2hZeVwNrOkNOMXTnLN4WxmSfG0hjVp9erVXHHpD6ipWYAkrrjqWjp16szVV17G++vWUdmhkot+cDkHDRxY7q5aif3ssq8x4ugDWbFyDUNOvRaAgfv05icXj6RTp46s37CRs6/9NbNefoNzTh/KV084FIAOlRXs1293+n7+QnbrtiO//OE3Pzxnv967ctW4P3DLPX8sxyW1G6lMaygiWrWB99bTug3k2A/GXsAhg4dwyldO5YP332fte+9x3rln8/XTz+DIoz7Hfz/5BHeOv5077vxlubva5rodOqbcXWhVRxzSn3feXcftV53+YTg/8NOz+Mndj/Po/7zCsCP35/+fcRzDvvWfmx13wtEH8r2vHcuIb/9ks/qKCrFw6jV87vQf8+fat9rsOtra2tm3bHO0/veCt4rOnKP26ZbbKE/lF11yZ82aNTz33ExO/vJXAOi43XZ07doVId5++x0A3l6zhu7de5Szm9ZK/uf5haxc9e5mdRHQdYfOAHxixy7Urli11XGnDR/CpEee26r+2MP25fUlK5IO5lKRii955mmNVrJ0yRK6dduFSy8ey/z589j/gAM4/8KLOf/Ci/hu1Wj+/YYfsnHjRibcfW+5u2pt5LwbfssDt57FdeecTEWFOPbMGzfb3qVzR447/B845/pJWx176rDB9Ya2bS3nmVu0Fo+cJX2jkW1VkmZJmnXHbdUtbaJd27BhPfNefYVTR45i0uTf06VLF8bfXs2kX0/kvAvG8uj0JzjvgrFcfsnF5e6qtZGqU4/i/Bt/x4ARl3D+DZMZd9nXNtv+xaMP4uk5i3hr9eYj7o4dKvni5w7id9Nmt2V3261KqejSFEmLJb0oaY6kWVndLpKmSXot+7NbVi9JN0uqkTRX0iHbch3bMq1xRUMbIqI6IoZExJDR36rahibar549d6dnz90ZOPBgAI47fjjzXn2FB+6/j6HHHQ/A8cNG8NKLc8vZTWtDX/unT/P76XMAmDxtNkMO+ORm208dNpjf1DM6Hnbk/syZ9ybLV65pi262f2pGKc6xETEoIoZk3y8EpkfEAGB69h1gBDAgK1XAuG25jEbDOUv/+sqLQM9taTh1u3XvTs/dd2fx64sAeGbG0+zdvz/de/Rg1sxnAXj2mRns+cm9ythLa0u1K1Zx1OABABxz2D7U/HnFh9u67tiZIwd/igf+uPU/1g3NQ1v91Iz/WuhE4K7s813ASQX1E6LODGBnSb1a2khTc849gWHAlnchBPyppY1+XFx40SWMveD7fPDBB/Tp05crr76OY44dyo+uv5YN69ezXadOXHr5leXuprWCu647k6MGD2C3nXek5pGruOpnD3HWVffw4/O+QocOFaxbt54xV0/8cP8vHXsw02fM49333t/sPNt33o7Pf3q/zfa1xjXnRp+kKupGuZtUR0ThXGwAj0oK4OfZtp4RUZtt/wsfDVR7A28WHLskq6ulBRpdSifpDuAXEfFUPdvuiYh/bqqBj/NSOmtY6kvprGVKsZRu5qJVRWfOoXt/otH2JPWOiKWSegDTgO8BUyJi54J93oqIbpIeBK7flJeSpgMXRMSsllxHoyPniBjdyLYmg9nMrM2VcLlGRCzN/lwu6T7gMGCZpF4RUZtNWyzPdl8K9C04vE9W1yJe52xmSamQii6NkbSDpJ02fQaOB14CpgBnZLudAdyffZ4CnJ6t2vgMsKpg+qPZvM7ZzJJSwoFzT+A+1YV4B+CeiHhE0kxgkqTRwBvAadn+DwEnADXAu0CDy42L4XA2s7SUKJ0jYhFwcD31fwOG1lMfwFmlad3hbGaJ8VvpzMxyKO/vzCiWw9nMkuJwNjPLIU9rmJnlkEfOZmY5lEg2O5zNLDGJpLPD2cyS4jlnM7McSuUHXh3OZpYWh7OZWf54WsPMLIe8lM7MLIcSyWaHs5klJpF0djibWVKaeol+e+FwNrOkpBHNDmczS00i6exwNrOkeCmdmVkOJTLl7HA2s7Q4nM3MciiVaY2KcnfAzKyUpOJL4+dRX0mPS3pF0suS/l9Wf7mkpZLmZOWEgmPGSqqRNF/SsG25Do+czSwpJRw3rwfOjYjnJe0EPCdpWrbtpoi4YbN2pf2BkcABwB7AY5L2iYgNLWncI2czS0qpRs4RURsRz2ef1wCvAr0bOeRE4N6IWBcRrwM1wGEtvQ6Hs5klRkUXSVWSZhWUqnrPKO0F/CPwTFY1RtJcSeMldcvqegNvFhy2hMbDvFEOZzNLSoWKLxFRHRFDCkr1lueTtCMwGTg7IlYD44D+wCCgFrixNa7Dc85mlpRSLqWT1JG6YL47In4HEBHLCrbfBjyYfV0K9C04vE9W1yIeOZtZUtSM/xo9jyTgDuDViPj3gvpeBbudDLyUfZ4CjJTUSVI/YADwbEuvwyNnM0tL6UbORwBfB16UNCeruwgYJWkQEMBi4NsAEfGypEnAK9St9DirpSs1wOFsZokpVTZHxFMNnO6hRo65BrimFO07nM0sKX5828wsh5RIOjuczSwpaUSzw9nMEpPIwNnhbGZpSeWtdA5nM0uKR85mZjnkcDYzyyFPa5iZ5ZBHzmZmOZRINjuczSwxiaSzw9nMkuI5ZzOzHKpII5sdzmaWGIezmVn+eFrDzCyHUllKp4godx8+NiRV1fcDkvbx5r8XVh//hmDbqvdn1+1jz38vbCsOZzOzHHI4m5nlkMO5bXle0erjvxe2Fd8QNDPLIY+czcxyyOFsZpZDDuc2Imm4pPmSaiRdWO7+WPlJGi9puaSXyt0Xyx+HcxuQVAncCowA9gdGSdq/vL2yHLgTGF7uTlg+OZzbxmFATUQsioj3gXuBE8vcJyuziHgSWFnuflg+OZzbRm/gzYLvS7I6M7N6OZzNzHLI4dw2lgJ9C773yerMzOrlcG4bM4EBkvpJ2g4YCUwpc5/MLMcczm0gItYDY4CpwKvApIh4uby9snKTNBF4GthX0hJJo8vdJ8sPP75tZpZDHjmbmeWQw9nMLIcczmZmOeRwNjPLIYezmVkOOZzNzHLI4WxmlkP/B8XVbInr4j7sAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " NonViolence       0.96      0.95      0.95      1640\n",
      "    Violence       0.96      0.97      0.96      1945\n",
      "\n",
      "    accuracy                           0.96      3585\n",
      "   macro avg       0.96      0.96      0.96      3585\n",
      "weighted avg       0.96      0.96      0.96      3585\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "corr_pred = metrics.confusion_matrix(y_test, preds)\n",
    "\n",
    "n_correct = np.int((corr_pred[0][0] + corr_pred[1][1]))\n",
    "print('> Correct Predictions:', n_correct)\n",
    "n_wrongs = np.int((corr_pred[0][1] + (corr_pred[1][0])))\n",
    "print('> Wrong Predictions:', n_wrongs)\n",
    "\n",
    "sns.heatmap(corr_pred,annot=True, fmt=\"d\",cmap=\"Blues\")\n",
    "plt.show()\n",
    "\n",
    "print(metrics.classification_report(y_test, preds, \n",
    "                           target_names=[\"NonViolence\", \"Violence\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yash\\anaconda3\\envs\\open_cv\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n"
     ]
    }
   ],
   "source": [
    "model.save(\"Model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### only 30% of data is used Model can be imporved "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "be644dce6777b1522c8dcdf601cc87590e2b9cf78600389fcab59418c0bfc805"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 64-bit ('open_cv': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
